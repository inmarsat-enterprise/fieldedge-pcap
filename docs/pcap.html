<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>fieldedge_pcap.pcap API documentation</title>
<meta name="description" content="A utility to parse and generate relevant metrics for analysis of a PCAP file …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>fieldedge_pcap.pcap</code></h1>
</header>
<section id="section-intro">
<p>A utility to parse and generate relevant metrics for analysis of a PCAP file.</p>
<p>Uses the <code>pyshark</code> package for capture and analysis.</p>
<ul>
<li>Goal is WAN data reduction, focus is on packet size and application type.</li>
<li>Ignore/filter out local traffic e.g. ARP</li>
<li>Identify repeating patterns based on size and application protocol
to derive an interval&hellip;can it be done less frequently or by proxy?
e.g. DNS cache, local NTP</li>
<li>If payload can be read (unencrypted) does it change often&hellip;could threshold
report by exception be used with a less frequent update pushed?</li>
</ul>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;A utility to parse and generate relevant metrics for analysis of a PCAP file.

Uses the `pyshark` package for capture and analysis.

* Goal is WAN data reduction, focus is on packet size and application type.
* Ignore/filter out local traffic e.g. ARP
* Identify repeating patterns based on size and application protocol
to derive an interval...can it be done less frequently or by proxy?
e.g. DNS cache, local NTP
* If payload can be read (unencrypted) does it change often...could threshold
report by exception be used with a less frequent update pushed?

&#34;&#34;&#34;
import asyncio
import io
import json
import logging
import os
import statistics
import sys
import traceback
from datetime import datetime
from enum import Enum
from multiprocessing import Queue
from pathlib import Path

import pyshark
from pyshark.capture.capture import TSharkCrashException
from pyshark.packet.packet import Packet as SharkPacket

_log = logging.getLogger(__name__)

LOCALNET_172 = str(os.getenv(&#39;LOCALNET_172&#39;, True)) == &#39;True&#39;
LOCALNET_192 = str(os.getenv(&#39;LOCALNET_192&#39;, True)) == &#39;True&#39;
DEBUG_PACKET_NUMBER = int(os.getenv(&#39;DEBUG_PACKET_NUMBER&#39;, 0))
DEBUG_VERBOSE = str(os.getenv(&#39;DEBUG_VERBOSE&#39;, False)).lower() == &#39;true&#39;


class EthernetProtocol(Enum):
    &#34;&#34;&#34;Mappings for Ethernet packet types.&#34;&#34;&#34;
    ETH_TYPE_EDP = 0x00bb  # Extreme Networks Discovery Protocol
    ETH_TYPE_PUP = 0x0200  # PUP protocol
    ETH_TYPE_IP = 0x0800  # IP protocol
    ETH_TYPE_ARP = 0x0806  # address resolution protocol
    ETH_TYPE_AOE = 0x88a2  # AoE protocol
    ETH_TYPE_CDP = 0x2000  # Cisco Discovery Protocol
    ETH_TYPE_DTP = 0x2004  # Cisco Dynamic Trunking Protocol
    ETH_TYPE_REVARP = 0x8035  # reverse addr resolution protocol
    ETH_TYPE_8021Q = 0x8100  # IEEE 802.1Q VLAN tagging
    ETH_TYPE_8021AD = 0x88a8  # IEEE 802.1ad
    ETH_TYPE_QINQ1 = 0x9100  # Legacy QinQ
    ETH_TYPE_QINQ2 = 0x9200  # Legacy QinQ
    ETH_TYPE_IPX = 0x8137  # Internetwork Packet Exchange
    ETH_TYPE_IP6 = 0x86DD  # IPv6 protocol
    ETH_TYPE_PPP = 0x880B  # PPP
    ETH_TYPE_MPLS = 0x8847  # MPLS
    ETH_TYPE_MPLS_MCAST = 0x8848  # MPLS Multicast
    ETH_TYPE_PPPOE_DISC = 0x8863  # PPP Over Ethernet Discovery Stage
    ETH_TYPE_PPPOE = 0x8864  # PPP Over Ethernet Session Stage
    ETH_TYPE_LLDP = 0x88CC  # Link Layer Discovery Protocol
    ETH_TYPE_TEB = 0x6558  # Transparent Ethernet Bridging


class KnownTcpPorts(Enum):
    &#34;&#34;&#34;Mappings for common registered/known application layer TCP ports.&#34;&#34;&#34;
    SMTP = 25
    HTTP = 80
    HTTP_TLS = 443
    DNS = 53
    FTP = 20
    FTPC = 21
    TELNET = 23
    IMAP = 143
    RDP = 3389
    SSH = 22
    HTTP2 = 8080
    MODBUS = 502
    MODBUS_TLS = 802
    MQTT = 1883
    MQTT_TLS = 8883
    MQTT_SOCKET = 9001
    DOCKERAPI = 2375
    DOCKERAPI_TLS = 2376
    SRCP = 4303
    COAP = 5683
    COAP_TLS = 5684
    DNP2 = 19999
    DNP = 20000
    IEC60870 = 2404


class KnownUdpPorts(Enum):
    &#34;&#34;&#34;Mappings for common registered/known application layer TCP ports.&#34;&#34;&#34;
    SNMP = 161
    DNS = 53
    DHCP_QUERY = 67
    DHCP_RESPONSE = 68
    NTP = 123


def _get_src_dst(packet: SharkPacket) -&gt; &#39;tuple[str,str]&#39;:
    &#34;&#34;&#34;Returns the packet source and destination hosts as a tuple.
    
    Args:
        packet: A pyshark Packet
    
    Returns:
        A tuple with (source, destination) IP addresses
    &#34;&#34;&#34;
    if hasattr(packet, &#39;arp&#39;):
        return (str(packet.arp.src_proto_ipv4), str(packet.arp.dst_proto_ipv4))
    elif hasattr(packet, &#39;ip&#39;):
        return (str(packet.ip.src), str(packet.ip.dst))
    elif hasattr(packet, &#39;ipv6&#39;):
        # return (str(packet.ipv6.src), str(packet.ipv6.dst))
        raise NotImplementedError(f&#39;IPV6 unsupported&#39;)
    else:
        raise NotImplementedError(f&#39;Unable to determine src/dst&#39;
                                  f&#39; for {packet.highest_layer}&#39;)


def _get_ports(packet: SharkPacket) -&gt; tuple:
    &#34;&#34;&#34;Returns the transport source and destination ports as a tuple.
    
    Args:
        packet: A pyshark Packet

    Returns:
        A tuple with (source, destination) ports (TCP or UDP)
    &#34;&#34;&#34;
    if packet.transport_layer:
        srcport = int(packet[packet.transport_layer].srcport)
        dstport = int(packet[packet.transport_layer].dstport)
    elif hasattr(packet, &#39;icmp&#39;) and packet[&#39;icmp&#39;].udp_port:
        srcport = int(packet[&#39;icmp&#39;].udp_srcport)
        dstport = int(packet[&#39;icmp&#39;].udp_dstport)
    else:
        raise ValueError(&#39;Unable to determine transport&#39;
                            f&#39; for {packet.highest_layer} packet&#39;)
    return (srcport, dstport)


def _get_application(packet: SharkPacket) -&gt; str:
    &#34;&#34;&#34;Returns the application layer descriptor.
    
    If the port is a registered port it will return a caps string.

    Args:
        packet: A pyshark Packet

    Returns:
        A string with the application layer protocol e.g. `TCP_MQTTS`
    &#34;&#34;&#34;
    highest_layer: str = packet.highest_layer
    transport_layer: str = &#39;&#39;
    if packet.transport_layer:
        transport_layer = packet.transport_layer
    else:
        try:
            transport_layer = str(packet.layers[2].layer_name).upper()
        except Exception as err:
            _log.error(err)
    application = &#39;&#39;
    if hasattr(packet[highest_layer], &#39;app_data_proto&#39;):
        application = str(packet[highest_layer].app_data_proto).upper()
    if transport_layer:
        if not application:
            (srcport, dstport) = _get_ports(packet)
            ports_lookup = None
            if transport_layer == &#39;TCP&#39;:
                ports_lookup = KnownTcpPorts
            elif transport_layer == &#39;UDP&#39;:
                ports_lookup = KnownUdpPorts
            if ports_lookup:
                known_ports = tuple(item.value for item in ports_lookup)
                if srcport in known_ports:
                    application = ports_lookup(srcport).name
                elif dstport in known_ports:
                    application = ports_lookup(dstport).name
            else:
                if transport_layer != highest_layer:
                    application = highest_layer.upper()
                else:
                    application += f&#39;{dstport}&#39;
        application = f&#39;{transport_layer}_{application}&#39;
    # identified workarounds for observed pyshark/tshark app_data_proto
    if not application:
        application = f&#39;{str(packet.highest_layer).upper()}_UNKNOWN&#39;
    application = application.replace(&#39;HTTP-OVER-TLS&#39;, &#39;HTTP_TLS&#39;)
    if highest_layer == &#39;TLS&#39; and not application.endswith(&#39;_TLS&#39;):
        application += &#39;_TLS&#39;
    if not (application.startswith(&#39;TCP_&#39;) or application.startswith(&#39;UDP_&#39;)):
        _log.warning(f&#39;Transport layer unknown for packet {packet.number}&#39;)
    return application


def is_valid_ip(ip_addr: str) -&gt; bool:
    &#34;&#34;&#34;Returns true if the string represents a valid IPv4 address.
    
    Args:
        ip_addr: The IP address being qualified
    
    Returns:
        True if it has 4 parts separated by `.` with each part in range 0..255
    &#34;&#34;&#34;
    if not(isinstance(ip_addr, str)):
        return False
    if (len(ip_addr.split(&#39;.&#39;)) == 4 and
        (int(x) in range (0,256) for x in ip_addr.split(&#39;.&#39;))):
        return True
    return False


def is_private_ip(ip_addr: str) -&gt; bool:
    &#34;&#34;&#34;Returns true if the IPv4 address is in the private range.
    
    Args:
        ip_addr: The IP address being qualified
    
    Returns:
        True if the address is in the private range(s)
    
    Raises:
        ValueError if the address is invalid
    &#34;&#34;&#34;
    if not is_valid_ip(ip_addr):
        raise ValueError(f&#39;IP address must be a valid IPv4 x.x.x.x&#39;)
    if (ip_addr.startswith(&#39;10.&#39;) or
        (ip_addr.startswith(&#39;172.&#39;) and
        int(ip_addr.split(&#39;.&#39;)[1]) in range(16, 32)) or
        ip_addr.startswith(&#39;192.168.&#39;)):
        return True
    return False


def _is_localnet_172(addr: str) -&gt; bool:
    if (addr.startswith(&#39;172.&#39;) and
        int(addr.split(&#39;.&#39;)[1] in range(16, 31 + 1))):
        return True
    return False


def _is_localnet_192(addr: str) -&gt; bool:
    if addr.startswith(&#39;192.168.&#39;):
        return True
    return False


def _is_same_subnet(src: str, dst: str) -&gt; bool:
    src_parts = src.split(&#39;.&#39;)
    dst_parts = dst.split(&#39;.&#39;)
    for part in range(0, 3):
        if src_parts[part] != dst_parts[part]:
            return False
    return True


def _is_multicast(addr: str) -&gt; bool:
    MULTICAST_RANGE = (224, 239 + 1)
    first_octet = int(addr.split(&#39;.&#39;)[0])
    if first_octet == 255:
        return True
    elif first_octet in range(MULTICAST_RANGE[0], MULTICAST_RANGE[1]):
        return True
    return False


def _is_local_traffic(packet: SharkPacket) -&gt; bool:
    &#34;&#34;&#34;Returns true if the source is on the LAN and destinations are cast.
    
    Args:
        packet: A pyshark Packet capture
    
    Returns:
        True if both addresses are in the LAN range 192.168.x.y 
    &#34;&#34;&#34;
    src, dst = _get_src_dst(packet)
    if LOCALNET_172:
        if (_is_localnet_172(src) and _is_localnet_172(dst) and
            _is_same_subnet(src, dst)):
            # if DEBUG_VERBOSE:
            #     _log.debug(f&#39;Local LAN packet {src} -&gt; {dst}&#39;)
            return True
        if ((_is_localnet_172(src) and _is_multicast(dst)) or
            (_is_multicast(src) and _is_localnet_172(dst))):
            # if DEBUG_VERBOSE:
            #     _log.debug(f&#39;Local multicast packet {src} -&gt; {dst}&#39;)
            return True
    if LOCALNET_192:
        if (_is_localnet_192(src) and _is_localnet_192(dst) and
            _is_same_subnet(src, dst)):
            # if DEBUG_VERBOSE:
            #     _log.debug(f&#39;Local LAN packet {src} -&gt; {dst}&#39;)
            return True
        if ((_is_localnet_192(src) and _is_multicast(dst)) or
            (_is_multicast(src) and _is_localnet_192(dst))):
            # if DEBUG_VERBOSE:
            #     _log.debug(f&#39;Local multicast packet {src} -&gt; {dst}&#39;)
            return True
    if _is_multicast(src) and _is_multicast(dst):
        # if DEBUG_VERBOSE:
        #     _log.debug(f&#39;Local multicast packet {src} -&gt; {dst}&#39;)
        return True
    return False


def _is_tcp_reset(packet: SharkPacket) -&gt; bool:
    # TODO: look for RST flag
    raise NotImplementedError


def _check_flags(packet: SharkPacket) -&gt; &#39;dict|None&#39;:
    # TODO: tcp.analysis.flags &amp;&amp; !tcp.analysis.window_update &amp;&amp; !tcp.analysis.keep_alive &amp;&amp; !tcp.analysis.keep_alive_ack
    # TODO: tcp.analysis.retransmission
    IGNORE = [
        &#39;analysis_flags&#39;,
    ]
    if hasattr(packet, &#39;tcp&#39;) and hasattr(packet.tcp, &#39;analysis_flags&#39;):
        bad_packet = {}
        for attr in dir(packet.tcp):
            if attr.startswith(&#39;analysis_&#39;) and attr not in IGNORE:
                bad_packet[attr] = getattr(packet.tcp, attr)
        return bad_packet


def _clean_path(pathname: str) -&gt; str:
    &#34;&#34;&#34;Adjusts relative and shorthand filenames for OS independence.
    
    Args:
        pathname: The full path/to/file
    
    Returns:
        A clean file/path name for the current OS and directory structure.
    &#34;&#34;&#34;
    if pathname.startswith(&#39;$HOME/&#39;):
        pathname = pathname.replace(&#39;$HOME&#39;, str(Path.home()), 1)
    elif pathname.startswith(&#39;~/&#39;):
        pathname = pathname.replace(&#39;~&#39;, str(Path.home()), 1)
    if os.path.isdir(os.path.dirname(pathname)):
        return os.path.realpath(pathname)
    else:
        raise ValueError(f&#39;Directory {os.path.dirname(pathname)} not found&#39;)


class SimplePacket:
    &#34;&#34;&#34;A simplified packet representation.
    
    Attributes:
        a_b (bool): Direction of travel relative to parent conversation
        application (str): The analysis-derived application
        highest_layer (str): The highest Wireshark-derived packet layer
        timestamp (float): The unix timestamp of the capture to 3 decimal places
        size (int): Size in bytes
        transport (str): The transport type
        src (str): Source IP address
        dst (str): Destination IP address
        srcport (int): Source port
        dstport (int): Destination port
        bad_packet (dict): Metadata present if the packet is suspected to be bad

    &#34;&#34;&#34;
    def __init__(self, packet: SharkPacket, parent_hosts: tuple) -&gt; None:
        self._parent_hosts = parent_hosts
        self.timestamp = round(float(packet.sniff_timestamp), 3)
        self.size = int(packet.length)
        self.transport = packet.transport_layer
        if packet.transport_layer:
            self.transport = packet.transport_layer
            self.stream_id = str(packet[self.transport].stream)
        elif hasattr(packet, &#39;icmp&#39;) and packet[&#39;icmp&#39;].udp_port:
            self.transport = &#39;UDP&#39;
            self.stream_id = str(packet[&#39;icmp&#39;].udp_stream)
        else:
            raise ValueError(&#39;Unable to determine transport&#39;
                                f&#39; for {packet.highest_layer} packet&#39;)
        self.src, self.dst = _get_src_dst(packet)
        self.srcport, self.dstport = _get_ports(packet)
        self.highest_layer = str(packet.highest_layer).upper()
        self.application = _get_application(packet)
        self.a_b = True if self.src == self._parent_hosts[0] else False
        self.bad_packet = _check_flags(packet)


class Conversation:
    &#34;&#34;&#34;Encapsulates all traffic between two endpoints.
    
    Attributes:
        application: The dominant application layer
        hosts: A tuple of IP addresses (host A, host B)
        a_b: The count of transactions from host A to host B
        b_a: The count of transactions from host B to host A
        stream_id: The stream ID from the tshark capture
        transport: The transport used e.g. TCP, UDP
        ports: A list of transport ports used e.g. [1883]
        start_ts: The unix timestamp of the first packet sent
        packets: A list of all the packets summarized
        packet_count: The size of the packets list
        bytes_total: The total number of bytes in the conversation
        bad_packet_count: The number of suspected bad packets
            (includes retransmit)
        bytes_bad: The byte count of the suspected bad packets
            (includes retransmitted bytes)
        retransmit_count: The number of suspected retransmitted packets
        bytes_retransmit: The total retransmitted bytes

    &#34;&#34;&#34;
    def __init__(self, packet: SharkPacket = None, number: int = None):
        self.number = number
        self.application: str = None
        self.hosts: tuple = None
        self.a_b: int = 0
        self.b_a: int = 0
        self.stream_id: str = None
        self.transport: str = None
        self.ports: list = []
        self.packets: &#39;list[SimplePacket]&#39; = []
        self.packet_count: int = 0
        self.bad_packet_count: int = 0
        self.retransmit_count: int = 0
        self.bytes_total: int = 0
        self.bytes_bad: int = 0
        self.bytes_retransmit: int = 0
        self.start_ts: float = None
        if packet is not None:
            self.packet_add(packet)
    
    def __repr__(self) -&gt; str:
        return json.dumps(vars(self), indent=2)

    def is_packet_in_flow(self, packet: SharkPacket) -&gt; bool:
        &#34;&#34;&#34;Returns True if the packet is between the object&#39;s hosts.
        
        Args:
            packet: A pyshark Packet capture
        
        Returns:
            True if the packet source and destination are the hosts.
        &#34;&#34;&#34;
        if self.hosts is None:
            return False
        (src, dst) = _get_src_dst(packet)
        if _is_local_traffic(packet):
            return False
        stream_id = None
        if packet.transport_layer:
            transport = packet.transport_layer
            try:
                stream_id = packet[transport].stream
            except AttributeError as err:
                _log.exception(f&#39;{err}&#39;)
        elif hasattr(packet, &#39;icmp&#39;) and packet[&#39;icmp&#39;].udp_stream:
            stream_id = packet[&#39;icmp&#39;].udp_stream
        if (src in self.hosts and dst in self.hosts and
            stream_id is not None and
            stream_id == self.stream_id):
            return True
        return False
    
    def packet_add(self, packet: SharkPacket) -&gt; bool:
        &#34;&#34;&#34;Adds the packet summary and metadata to the Conversation.
        
        Args:
            packet: A pyshark Packet capture
        
        Returns:
            True if the packet was added to the Conversation.
        
        Raises:
            ValueError if the packet is missing transport_layer or has a
                different transport or stream ID than the conversation.

        &#34;&#34;&#34;
        if not(isinstance(packet, SharkPacket)):
            raise ValueError(&#39;packet is not a valid pyshark Packet&#39;)
        if self.hosts is None:
            self.hosts = _get_src_dst(packet)
        elif not(self.is_packet_in_flow(packet)):
            _log.warning(f&#39;Packet {packet.number} not in flow {self.number}&#39;)
            return False
        try:
            simple_packet = SimplePacket(packet, self.hosts)
        except Exception as err:
            _log.error(err)
            raise err
        isotime = datetime.utcfromtimestamp(simple_packet.timestamp).isoformat()[0:23]
        if DEBUG_VERBOSE:
            _log.debug(f&#39;Adding packet {packet.number}&#39;
                       f&#39; to conversation {self.number or 0}:&#39;
                       f&#39;{isotime}|{simple_packet.application}|&#39;
                       f&#39;({simple_packet.transport}.{simple_packet.stream_id}&#39;
                       f&#39;:{simple_packet.dstport})&#39;
                       f&#39;|{simple_packet.size} bytes&#39;
                       f&#39;|{simple_packet.src}--&gt;{simple_packet.dst}&#39;)
        if simple_packet.src == self.hosts[0]:
            self.a_b += 1
        else:
            self.b_a += 1
        if self.transport is None:
            self.transport = simple_packet.transport
        if simple_packet.srcport not in self.ports:
            self.ports.append(simple_packet.srcport)
        if simple_packet.dstport not in self.ports:
            self.ports.append(simple_packet.dstport)
        if self.stream_id is None:
            self.stream_id = simple_packet.stream_id
        elif simple_packet.stream_id != self.stream_id:
            err = (f&#39;Packet {packet.number} expected stream {self.stream_id}&#39;
                   f&#39; but got {simple_packet.stream_id}&#39;)
            _log.error(err)
            raise ValueError(err)
        self.packet_count += 1
        self.bytes_total += simple_packet.size
        if self.start_ts is None:
            self.start_ts = simple_packet.timestamp
        try:
            if simple_packet.bad_packet:
                if &#39;analysis_retransmission&#39; in simple_packet.bad_packet:
                    self.retransmit_count += 1
                    self.bytes_retransmit += simple_packet.size
                self.bad_packet_count += 1
                self.bytes_bad += simple_packet.size
                if DEBUG_VERBOSE:
                    _log.debug(f&#39;Bad packet {packet.number}&#39;
                               f&#39; ({simple_packet.bad_packet})&#39;)
            self.packets.append(simple_packet)
            if self.application is None:
                self.application = simple_packet.application
            elif self.application != simple_packet.application:
                _log.warning(f&#39;Packet {packet.number}&#39;
                             f&#39; expected application {self.application}&#39;
                             f&#39; but got {simple_packet.application}&#39;)
            return True
        except Exception as err:
            _log.exception(err)
            raise err
        
    @staticmethod
    def _get_intervals_by_length(packets_by_size: dict) -&gt; dict:
        intervals = {}
        for packet_size in packets_by_size:
            packet_list: list[SimplePacket] = packets_by_size[packet_size]
            intervals[packet_size] = None
            if len(packet_list) == 1:
                application = packet_list[0].application
                application += f&#39;_{packet_size}B&#39;
                intervals[application] = None
                del intervals[packet_size]
                continue
            is_same_application = True   # starting assumption
            for i, packet in enumerate(packet_list):
                if i == 0:
                    # skip the first one since we are looking for time between
                    continue
                if (packet_list[i - 1].application != packet.application):
                    is_same_application = False
                this_interval = (
                    packet.timestamp - packet_list[i - 1].timestamp
                )
                if intervals[packet_size] is None:
                    intervals[packet_size] = this_interval
                else:
                    intervals[packet_size] = (round((intervals[packet_size] +
                                              this_interval) / 2, 3))
            if is_same_application:
                application = packet_list[0].application
            else:
                application = &#39;mixed&#39;
            application += f&#39;_{packet_size}B&#39;
            intervals[application] = intervals[packet_size]
            del intervals[packet_size]
        return intervals
    
    def data_series_packet_size(self) -&gt; list:
        &#34;&#34;&#34;Generates a data series with timestamp and packet size.

        Example: [(12345.78, 42), (12355.99, 42)]

        Returns:
            A list of tuples consisting of (unix_timestamp, size_bytes)

        &#34;&#34;&#34;
        series = []
        for packet in self.packets:
            datapoint = (packet.timestamp, packet.size)
            series.append(datapoint)
        return series

    def data_series_packet_size_good_bad(self) -&gt; &#39;tuple[list, list]&#39;:
        good_series = []
        bad_series = []
        for packet in self.packets:
            datapoint = (packet.timestamp, packet.size)
            if not packet.bad_packet:
                good_series.append(datapoint)
            else:
                bad_series.append(datapoint)
        return (good_series, bad_series)

    def group_packets_by_size(self) -&gt; tuple:
        &#34;&#34;&#34;Creates dictionaries keyed by similar packet size and direction.
        
        Returns:
            A tuple with 2 dictionaries representing flows A-B and B-A.
            In each dictionary the keys are the packet size and the value
                is a list of the packets of that size.

        &#34;&#34;&#34;
        packets_a_b = {}
        packets_b_a = {}
        lengths = []
        for packet in self.packets:
            if packet.a_b:
                if packet.size not in packets_a_b:
                    packets_a_b[packet.size] = list()
                packets_a_b[packet.size].append(packet)
            else:
                if packet.size not in packets_b_a:
                    packets_b_a[packet.size] = list()
                packets_b_a[packet.size].append(packet)
            lengths.append(packet.size)
        return (packets_a_b, packets_b_a)

    def intervals(self) -&gt; dict:
        &#34;&#34;&#34;Analyzes the conversation and returns metrics in a dictionary.
        
        Returns:
            A dictionary including:
                * A (str): The host IP that initiated the conversation
                * B (str): The host IP opposite to A
                * AB_intervals (dict): A dictionary with grouped packet size
                average repeat interval A to B in seconds
                * AB_intervals (dict): A dictionary with grouped packet size
                average repeat interval B to A in seconds

        &#34;&#34;&#34;
        # sort by direction and packet size
        packets_a_b, packets_b_a = self.group_packets_by_size()
        # TODO: dominant packet list based on quantity * size
        return {
            &#39;hosts&#39;: self.hosts,
            &#39;AB_intervals&#39;: self._get_intervals_by_length(packets_a_b),
            &#39;BA_intervals&#39;: self._get_intervals_by_length(packets_b_a)
        }


class PacketStatistics:
    &#34;&#34;&#34;Encapsulates packet-level statistics from a capture over time.
    
    Attributes:
        conversations (list): A list of Conversation elements for analyses.
        packet_count (int): The total number of packets
        bytes_total (int): The total amount of data in bytes

    &#34;&#34;&#34;
    def __init__(self,
                 source_filename: str = None,
                 ) -&gt; None:
        &#34;&#34;&#34;Creates a PacketStatistics object.
        
        Args:
            source_filename: An optional tie to the source pcap file

        &#34;&#34;&#34;
        self._source_filename: str = source_filename
        self.conversations: list[Conversation] = []
        self._packet_count: int = 0
        self._unhandled_packet_types: list = []
        self._unhandled_packet_count: int = 0
        self._local_packet_count: int = 0
        self._bytes_total: int = 0
        self._unhandled_bytes: int = 0
        self._local_bytes: int = 0
        self._first_packet_ts: float = None
        self._last_packet_ts: float = None
    
    @property
    def packet_count(self) -&gt; int:
        return self._packet_count
    
    @property
    def bytes_total(self) -&gt; int:
        return self._bytes_total
    
    @property
    def duration(self) -&gt; int:
        duration = int(self._last_packet_ts - self._first_packet_ts)
        if self._source_filename is not None:
            fileparts = str(self._source_filename.split(&#39;.pcap&#39;)[0]).split(&#39;_&#39;)
            try:
                file_duration = int(fileparts[len(fileparts) - 1])
                duration = max(file_duration, duration)
            except:
                pass
        return duration
    
    def packet_add(self, packet: SharkPacket) -&gt; None:
        &#34;&#34;&#34;Adds a packet to the statistics for analyses.
        
        Args:
            packet: A pyshark Packet object.

        &#34;&#34;&#34;
        self._packet_count += 1
        self._bytes_total += int(packet.length)
        ts = round(float(packet.sniff_timestamp), 3)
        if self._first_packet_ts is None:
            self._first_packet_ts = ts
        self._last_packet_ts = ts
        if hasattr(packet, &#39;arp&#39;):
            self._process_arp(packet)
        elif hasattr(packet, &#39;tcp&#39;) or hasattr(packet, &#39;udp&#39;):
            self._process_ip(packet)
        elif hasattr(packet, &#39;icmp&#39;):
            self._process_ip(packet)
        else:
            self._process_unhandled(packet)
    
    def _process_arp(self, packet: SharkPacket):
        arp_desc = f&#39;{packet.arp.src_proto_ipv4}--&gt;{packet.arp.dst_proto_ipv4}&#39;
        if not _is_local_traffic(packet):
            _log.warning(f&#39;Non-local ARP packet {arp_desc}&#39;)
        else:
            if DEBUG_VERBOSE:
                _log.debug(f&#39;Local ARP {arp_desc} (ignored from statistics)&#39;)

    def _process_ip(self, packet: SharkPacket):
        in_conversation = False
        if _is_local_traffic(packet):
            if DEBUG_VERBOSE:
                _log.debug(f&#39;Ignoring packet {packet.number} local traffic&#39;)
            self._local_packet_count += 1
            self._local_bytes += int(packet.length)
            return
        for conversation in self.conversations:
            if conversation.is_packet_in_flow(packet):
                conversation.packet_add(packet)
                in_conversation = True
                break
        if not in_conversation:
            conversation_number = len(self.conversations) + 1
            if DEBUG_VERBOSE:
                _log.debug(f&#39;Found new conversation ({conversation_number})&#39;)
            conversation = Conversation(packet, conversation_number)
            self.conversations.append(conversation)

    def _process_unhandled(self, packet: SharkPacket):
        packet_type = packet.highest_layer
        self._unhandled_packet_count += 1
        self._unhandled_bytes += int(packet.length)
        if packet_type not in self._unhandled_packet_types:
            _log.warning(f&#39;Packet {packet.number}&#39;
                         f&#39; unhandled packet type {packet_type}&#39;)
            self._unhandled_packet_types.append(packet_type)

    def data_series_application_size(self, split_bad: bool = False) -&gt; dict:
        &#34;&#34;&#34;Returns a set of data series by conversation application.
        
        Example: {&#39;MQTT&#39;: [(12345.67, 42)]}

        Args:
            split_bad: if True will split out bad packets as a series.

        Returns:
            A dictionary with keys showing the application and values are
                tuples with (unix_timestamp, size_in_bytes)

        &#34;&#34;&#34;
        multi_series = {}
        for conversation in self.conversations:
            app = conversation.application
            if app in multi_series:
                multi_series[app] = (multi_series[app] +
                    conversation.data_series_packet_size())
            else:
                multi_series[app] = conversation.data_series_packet_size()
            multi_series[app].sort(key=lambda tup: tup[0])
        return multi_series

    def analyze_conversations(self) -&gt; dict:
        &#34;&#34;&#34;Analyzes all conversations to produce a summary.
        
        Returns:
            A dict with keys as unique host pairs &#34;(&#39;A&#39;, &#39;B&#39;)&#34; summary dict:
                {
                    count: `int`,
                    applications: `list[str]`,
                    start_times: `list[float]`,
                    packet_intervals: {
                        AB_intervals: {
                            &#39;&lt;transport&gt;_&lt;protocol&gt;_&lt;bytesize&gt;&#39;: `int`|`None`,
                        },
                        BA_intervals: {
                            &#39;&lt;transport&gt;_&lt;protocol&gt;_&lt;bytesize&gt;&#39;: `int`|`None`,
                        }
                    },
                    repeat_mean: `int`,
                    repeat_stdev: `int`
                }

        &#34;&#34;&#34;
        results = {}
        for conversation in self.conversations:
            hosts_str = str(conversation.hosts)
            intervals = conversation.intervals()
            intervals.pop(&#39;hosts&#39;, None)
            bad_packet_count = conversation.bad_packet_count
            if hosts_str not in results:
                results[hosts_str] = {
                    &#39;count&#39;: 1,
                    &#39;applications&#39;: [conversation.application],
                    &#39;start_times&#39;: [conversation.start_ts],
                    &#39;packet_intervals&#39;: intervals,
                    &#39;bytes&#39;: conversation.bytes_total,
                    &#39;bad_packet_count&#39;: bad_packet_count,
                    &#39;bytes_bad&#39;: conversation.bytes_bad,
                    &#39;retransmit_count&#39;: conversation.retransmit_count,
                    &#39;retransmit_bytes&#39;: conversation.bytes_retransmit,
                }
            else:
                results[hosts_str][&#39;count&#39;] += 1
                app = conversation.application
                if app not in results[hosts_str][&#39;applications&#39;]:
                    results[hosts_str][&#39;applications&#39;].append(app)
                results[hosts_str][&#39;start_times&#39;].append(conversation.start_ts)
                prior = results[hosts_str][&#39;packet_intervals&#39;]
                results[hosts_str][&#39;packet_intervals&#39;] = {**prior, **intervals}
                results[hosts_str][&#39;bad_packet_count&#39;] += bad_packet_count
        for key in results:
            times = results[key][&#39;start_times&#39;]
            results[key][&#39;repeat_mean&#39;] = None
            results[key][&#39;repeat_stdev&#39;] = None
            if len(times) == 1:
                continue
            intervals = []
            for i, ts in enumerate(times):
                if i == 0:
                    continue
                intervals.append(ts - times[i - 1])
            if len(intervals) &gt; 1:
                results[key][&#39;repeat_mean&#39;] = int(statistics.mean(intervals))
                results[key][&#39;repeat_stdev&#39;] = int(statistics.stdev(intervals))
        return results
    
    def unique_host_pairs(self) -&gt; &#39;list[tuple]&#39;:
        &#34;&#34;&#34;Lists unique host pairs as tuples.&#34;&#34;&#34;
        results = []
        for conversation in self.conversations:
            if conversation.hosts not in results:
                results.append(conversation.hosts)
        return results


def _get_event_loop() -&gt; tuple:
    loop_is_new = False
    try:
        loop: asyncio.AbstractEventLoop = asyncio.get_running_loop()
    except RuntimeError as err:
        if &#39;no running event loop&#39; not in f&#39;{err}&#39;:
            raise err
        loop = asyncio.new_event_loop()
        loop_is_new = True
    asyncio.set_event_loop(loop)
    asyncio.get_child_watcher().attach_loop(loop)
    return loop, loop_is_new


def process_pcap(filename: str,
                 display_filter: str = None,
                 queue: Queue = None,
                 debug: bool = False,
                 ) -&gt; PacketStatistics:
    &#34;&#34;&#34;Processes a PCAP file to create metrics for conversations.

    To run in the background use a multiprocessing.Process and Queue:
    ```
    import multiprocessing
    import queue

    q = multiprocessing.Queue()
    kwargs = {
        &#39;filename&#39;: filename,
        &#39;display_filter&#39;: display_filter,
        &#39;queue&#39;: q,
    }
    process = multiprocessing.Process(target=process_pcap,
                                      name=&#39;packet_capture&#39;,
                                      kwargs=kwargs)
    process.start()
    while process.is_alive():
        try:
            while True:
                packet_statistics = q.get(block=False)
        except queue.Empty:
            pass
    process.join()
    ```
    
    Args:
        filename: The path/name of the PCAP file
        display_filter: An optional tshark display filter
        queue: An optional multiprocessing Queue (e.g. required for Flask)
        debug: Enables pyshark debug output
    
    Returns:
        A PacketStatistics object with data and analytics functions.

    &#34;&#34;&#34;
    packet_stats = PacketStatistics(source_filename=filename)
    file = _clean_path(filename)
    loop: asyncio.AbstractEventLoop = None
    loop_is_new = False
    if queue is not None:
        loop, loop_is_new = _get_event_loop()
    capture = pyshark.FileCapture(input_file=file,
                                  display_filter=display_filter,
                                  eventloop=loop)
    capture.set_debug(debug)
    packet_number = 0
    handled_exceptions = []
    for packet in capture:
        assert isinstance(packet, SharkPacket)
        packet_number += 1
        # DEV: Uncomment below for specific step-through troubleshooting
        if DEBUG_PACKET_NUMBER and packet_number == DEBUG_PACKET_NUMBER:
            _log.info(f&#39;Investigate packet: {int(packet.number)}&#39;)
        try:
            packet_stats.packet_add(packet)
        except NotImplementedError as err:
            if str(err) not in handled_exceptions:
                sio = io.StringIO()
                ei = sys.exc_info()
                tb = ei[2]
                traceback.print_exception(ei[0], ei[1], tb, None, sio)
                s = sio.getvalue()
                sio.close()
                stack = s.split(&#39;\n&#39;)
                #: each stack call is 2 lines, the last 2 lines are the error
                #:   so the last call meta is 4-deep and the call itself 3-deep
                last_call = stack[-4:-2]
                err_prefix = &#39;pyshark&#39;
                if &#39;fieldedge_pcap/pcap.py&#39; in last_call[0]:
                    err_prefix = &#39;fieldedge_pcap&#39;
                _log.warning(f&#39;{err_prefix} (packet {packet.number}): {err}&#39;)
                handled_exceptions.append(str(err))
        except TSharkCrashException as err:
            _log.error(f&#39;tshark (packet {packet_number}): {err}&#39;)
            break
        except:
            #TODO: better error capture e.g. appears to have been cut short use editcap
            # https://tshark.dev/share/pcap_preparation/
            _log.exception(f&#39;Packet {packet_number} processing ERROR&#39;)
            break
    capture.close()
    if loop_is_new:
        loop.close()
    if queue is not None:
        queue.put(packet_stats)
    else:
        return packet_stats


def pcap_filename(duration: int, interface: str = &#39;&#39;) -&gt; str:
    &#34;&#34;&#34;Generates a pcap filename using datetime of the capture start.
    
    The datetime is UTC, and the duration is in seconds.

    Returns:
        A string formatted as `capture_YYYYmmddTHHMMSS_DDDDD.pcap`.

    &#34;&#34;&#34;
    dt = datetime.utcnow().isoformat().replace(&#39;-&#39;, &#39;&#39;).replace(&#39;:&#39;, &#39;&#39;)[0:15]
    filename = f&#39;capture_{dt}_{duration}&#39; + f&#39;_{interface}&#39; if interface else &#39;&#39;
    return f&#39;{filename}.pcap&#39;


def create_pcap(interface: str = &#39;eth1&#39;,
                duration: int = 60,
                filename: str = None,
                target_directory: str = &#39;$HOME&#39;,
                queue: Queue = None,
                debug: bool = False,
                **kwargs) -&gt; str:
    &#34;&#34;&#34;Creates a packet capture file of a specified interface.

    A subdirectory is created in the `target_directory`, if none is specified it
    stores to the user&#39;s home directory.
    The subdirectory name is `capture_YYYYmmdd`.
    The filename can be specified or `capture_YYYYmmddTHHMMSS_DDDDD.pcap`
    format will be used.
    To run in the background use a multiprocessing.Process and Queue:
    ```
    queue = multiprocessing.Queue()
    kwargs = {
        &#39;interface&#39;: my_interface,
        &#39;duration&#39;: my_duration,
        &#39;filename&#39;: pcap_filename(duration),
        &#39;target_directory&#39;: parent_folder,
        &#39;queue&#39;: queue,
    }
    capture_process = multiprocessing.Process(target=create_pcap,
                                              name=&#39;packet_capture&#39;,
                                              kwargs=kwargs)
    capture_process.start()
    capture_process.join()
    capture_file = queue.get()
    ```

    Often times the packet capture process will result in a corrupted file or
    have duplicate packets.
    To check for corruption run `tshark -r &lt;capture_file&gt;` which will have a
    returncode 2 if corrupt, and stderr will include
    &#39;appears to have been cut short&#39;.
    To fix a corrupted file run `editcap &lt;capture_file&gt; &lt;capture_file&gt;` which
    should have a returncode 0.
    
    Args:
        interface: The interface to capture from e.g. `eth1`.
        duration: The duration of the capture in seconds.
        target_directory: The path to save the capture to.
        queue: An optional queue to be passed in.
        debug: A flag to enable debug logging.
        kwargs: may include wireshark options e.g. `capture_filter`

    Returns:
        The full file/path name if no event is passed in.

    &#34;&#34;&#34;
    if filename is None:
        filename = pcap_filename(duration)
    target_directory = _clean_path(target_directory)
    subdir = f&#39;{target_directory}/{filename[0:len(&#34;capture_YYYYmmdd&#34;)]}&#39;
    filepath = f&#39;{subdir}/{filename}&#39;
    if not os.path.isdir(subdir):
        os.makedirs(subdir)
    loop: asyncio.AbstractEventLoop = None
    loop_is_new = False
    if queue is not None:
        loop, loop_is_new = _get_event_loop()
    capture = pyshark.LiveCapture(interface=interface,
                                  output_file=filepath,
                                  eventloop=loop,
                                  **kwargs)
    capture.set_debug(debug)
    capture.sniff(timeout=duration)
    capture.close()
    if loop_is_new:
        loop.close()
    if queue is not None:
        queue.put(filepath)
    else:
        return filepath</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="fieldedge_pcap.pcap.create_pcap"><code class="name flex">
<span>def <span class="ident">create_pcap</span></span>(<span>interface: str = 'eth1', duration: int = 60, filename: str = None, target_directory: str = '$HOME', queue: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x10c26bd68>> = None, debug: bool = False, **kwargs) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a packet capture file of a specified interface.</p>
<p>A subdirectory is created in the <code>target_directory</code>, if none is specified it
stores to the user's home directory.
The subdirectory name is <code>capture_YYYYmmdd</code>.
The filename can be specified or <code>capture_YYYYmmddTHHMMSS_DDDDD.pcap</code>
format will be used.
To run in the background use a multiprocessing.Process and Queue:</p>
<pre><code>queue = multiprocessing.Queue()
kwargs = {
    'interface': my_interface,
    'duration': my_duration,
    'filename': pcap_filename(duration),
    'target_directory': parent_folder,
    'queue': queue,
}
capture_process = multiprocessing.Process(target=create_pcap,
                                          name='packet_capture',
                                          kwargs=kwargs)
capture_process.start()
capture_process.join()
capture_file = queue.get()
</code></pre>
<p>Often times the packet capture process will result in a corrupted file or
have duplicate packets.
To check for corruption run <code>tshark -r &lt;capture_file&gt;</code> which will have a
returncode 2 if corrupt, and stderr will include
'appears to have been cut short'.
To fix a corrupted file run <code>editcap &lt;capture_file&gt; &lt;capture_file&gt;</code> which
should have a returncode 0.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>interface</code></strong></dt>
<dd>The interface to capture from e.g. <code>eth1</code>.</dd>
<dt><strong><code>duration</code></strong></dt>
<dd>The duration of the capture in seconds.</dd>
<dt><strong><code>target_directory</code></strong></dt>
<dd>The path to save the capture to.</dd>
<dt><strong><code>queue</code></strong></dt>
<dd>An optional queue to be passed in.</dd>
<dt><strong><code>debug</code></strong></dt>
<dd>A flag to enable debug logging.</dd>
<dt><strong><code>kwargs</code></strong></dt>
<dd>may include wireshark options e.g. <code>capture_filter</code></dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The full file/path name if no event is passed in.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_pcap(interface: str = &#39;eth1&#39;,
                duration: int = 60,
                filename: str = None,
                target_directory: str = &#39;$HOME&#39;,
                queue: Queue = None,
                debug: bool = False,
                **kwargs) -&gt; str:
    &#34;&#34;&#34;Creates a packet capture file of a specified interface.

    A subdirectory is created in the `target_directory`, if none is specified it
    stores to the user&#39;s home directory.
    The subdirectory name is `capture_YYYYmmdd`.
    The filename can be specified or `capture_YYYYmmddTHHMMSS_DDDDD.pcap`
    format will be used.
    To run in the background use a multiprocessing.Process and Queue:
    ```
    queue = multiprocessing.Queue()
    kwargs = {
        &#39;interface&#39;: my_interface,
        &#39;duration&#39;: my_duration,
        &#39;filename&#39;: pcap_filename(duration),
        &#39;target_directory&#39;: parent_folder,
        &#39;queue&#39;: queue,
    }
    capture_process = multiprocessing.Process(target=create_pcap,
                                              name=&#39;packet_capture&#39;,
                                              kwargs=kwargs)
    capture_process.start()
    capture_process.join()
    capture_file = queue.get()
    ```

    Often times the packet capture process will result in a corrupted file or
    have duplicate packets.
    To check for corruption run `tshark -r &lt;capture_file&gt;` which will have a
    returncode 2 if corrupt, and stderr will include
    &#39;appears to have been cut short&#39;.
    To fix a corrupted file run `editcap &lt;capture_file&gt; &lt;capture_file&gt;` which
    should have a returncode 0.
    
    Args:
        interface: The interface to capture from e.g. `eth1`.
        duration: The duration of the capture in seconds.
        target_directory: The path to save the capture to.
        queue: An optional queue to be passed in.
        debug: A flag to enable debug logging.
        kwargs: may include wireshark options e.g. `capture_filter`

    Returns:
        The full file/path name if no event is passed in.

    &#34;&#34;&#34;
    if filename is None:
        filename = pcap_filename(duration)
    target_directory = _clean_path(target_directory)
    subdir = f&#39;{target_directory}/{filename[0:len(&#34;capture_YYYYmmdd&#34;)]}&#39;
    filepath = f&#39;{subdir}/{filename}&#39;
    if not os.path.isdir(subdir):
        os.makedirs(subdir)
    loop: asyncio.AbstractEventLoop = None
    loop_is_new = False
    if queue is not None:
        loop, loop_is_new = _get_event_loop()
    capture = pyshark.LiveCapture(interface=interface,
                                  output_file=filepath,
                                  eventloop=loop,
                                  **kwargs)
    capture.set_debug(debug)
    capture.sniff(timeout=duration)
    capture.close()
    if loop_is_new:
        loop.close()
    if queue is not None:
        queue.put(filepath)
    else:
        return filepath</code></pre>
</details>
</dd>
<dt id="fieldedge_pcap.pcap.is_private_ip"><code class="name flex">
<span>def <span class="ident">is_private_ip</span></span>(<span>ip_addr: str) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Returns true if the IPv4 address is in the private range.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>ip_addr</code></strong></dt>
<dd>The IP address being qualified</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>True if the address is in the private range(s)</p>
<h2 id="raises">Raises</h2>
<p>ValueError if the address is invalid</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_private_ip(ip_addr: str) -&gt; bool:
    &#34;&#34;&#34;Returns true if the IPv4 address is in the private range.
    
    Args:
        ip_addr: The IP address being qualified
    
    Returns:
        True if the address is in the private range(s)
    
    Raises:
        ValueError if the address is invalid
    &#34;&#34;&#34;
    if not is_valid_ip(ip_addr):
        raise ValueError(f&#39;IP address must be a valid IPv4 x.x.x.x&#39;)
    if (ip_addr.startswith(&#39;10.&#39;) or
        (ip_addr.startswith(&#39;172.&#39;) and
        int(ip_addr.split(&#39;.&#39;)[1]) in range(16, 32)) or
        ip_addr.startswith(&#39;192.168.&#39;)):
        return True
    return False</code></pre>
</details>
</dd>
<dt id="fieldedge_pcap.pcap.is_valid_ip"><code class="name flex">
<span>def <span class="ident">is_valid_ip</span></span>(<span>ip_addr: str) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Returns true if the string represents a valid IPv4 address.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>ip_addr</code></strong></dt>
<dd>The IP address being qualified</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>True if it has 4 parts separated by <code>.</code> with each part in range 0..255</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_valid_ip(ip_addr: str) -&gt; bool:
    &#34;&#34;&#34;Returns true if the string represents a valid IPv4 address.
    
    Args:
        ip_addr: The IP address being qualified
    
    Returns:
        True if it has 4 parts separated by `.` with each part in range 0..255
    &#34;&#34;&#34;
    if not(isinstance(ip_addr, str)):
        return False
    if (len(ip_addr.split(&#39;.&#39;)) == 4 and
        (int(x) in range (0,256) for x in ip_addr.split(&#39;.&#39;))):
        return True
    return False</code></pre>
</details>
</dd>
<dt id="fieldedge_pcap.pcap.pcap_filename"><code class="name flex">
<span>def <span class="ident">pcap_filename</span></span>(<span>duration: int, interface: str = '') ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Generates a pcap filename using datetime of the capture start.</p>
<p>The datetime is UTC, and the duration is in seconds.</p>
<h2 id="returns">Returns</h2>
<p>A string formatted as <code>capture_YYYYmmddTHHMMSS_DDDDD.pcap</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pcap_filename(duration: int, interface: str = &#39;&#39;) -&gt; str:
    &#34;&#34;&#34;Generates a pcap filename using datetime of the capture start.
    
    The datetime is UTC, and the duration is in seconds.

    Returns:
        A string formatted as `capture_YYYYmmddTHHMMSS_DDDDD.pcap`.

    &#34;&#34;&#34;
    dt = datetime.utcnow().isoformat().replace(&#39;-&#39;, &#39;&#39;).replace(&#39;:&#39;, &#39;&#39;)[0:15]
    filename = f&#39;capture_{dt}_{duration}&#39; + f&#39;_{interface}&#39; if interface else &#39;&#39;
    return f&#39;{filename}.pcap&#39;</code></pre>
</details>
</dd>
<dt id="fieldedge_pcap.pcap.process_pcap"><code class="name flex">
<span>def <span class="ident">process_pcap</span></span>(<span>filename: str, display_filter: str = None, queue: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x10c26bd68>> = None, debug: bool = False) ‑> <a title="fieldedge_pcap.pcap.PacketStatistics" href="#fieldedge_pcap.pcap.PacketStatistics">PacketStatistics</a></span>
</code></dt>
<dd>
<div class="desc"><p>Processes a PCAP file to create metrics for conversations.</p>
<p>To run in the background use a multiprocessing.Process and Queue:</p>
<pre><code>import multiprocessing
import queue

q = multiprocessing.Queue()
kwargs = {
    'filename': filename,
    'display_filter': display_filter,
    'queue': q,
}
process = multiprocessing.Process(target=process_pcap,
                                  name='packet_capture',
                                  kwargs=kwargs)
process.start()
while process.is_alive():
    try:
        while True:
            packet_statistics = q.get(block=False)
    except queue.Empty:
        pass
process.join()
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filename</code></strong></dt>
<dd>The path/name of the PCAP file</dd>
<dt><strong><code>display_filter</code></strong></dt>
<dd>An optional tshark display filter</dd>
<dt><strong><code>queue</code></strong></dt>
<dd>An optional multiprocessing Queue (e.g. required for Flask)</dd>
<dt><strong><code>debug</code></strong></dt>
<dd>Enables pyshark debug output</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A PacketStatistics object with data and analytics functions.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_pcap(filename: str,
                 display_filter: str = None,
                 queue: Queue = None,
                 debug: bool = False,
                 ) -&gt; PacketStatistics:
    &#34;&#34;&#34;Processes a PCAP file to create metrics for conversations.

    To run in the background use a multiprocessing.Process and Queue:
    ```
    import multiprocessing
    import queue

    q = multiprocessing.Queue()
    kwargs = {
        &#39;filename&#39;: filename,
        &#39;display_filter&#39;: display_filter,
        &#39;queue&#39;: q,
    }
    process = multiprocessing.Process(target=process_pcap,
                                      name=&#39;packet_capture&#39;,
                                      kwargs=kwargs)
    process.start()
    while process.is_alive():
        try:
            while True:
                packet_statistics = q.get(block=False)
        except queue.Empty:
            pass
    process.join()
    ```
    
    Args:
        filename: The path/name of the PCAP file
        display_filter: An optional tshark display filter
        queue: An optional multiprocessing Queue (e.g. required for Flask)
        debug: Enables pyshark debug output
    
    Returns:
        A PacketStatistics object with data and analytics functions.

    &#34;&#34;&#34;
    packet_stats = PacketStatistics(source_filename=filename)
    file = _clean_path(filename)
    loop: asyncio.AbstractEventLoop = None
    loop_is_new = False
    if queue is not None:
        loop, loop_is_new = _get_event_loop()
    capture = pyshark.FileCapture(input_file=file,
                                  display_filter=display_filter,
                                  eventloop=loop)
    capture.set_debug(debug)
    packet_number = 0
    handled_exceptions = []
    for packet in capture:
        assert isinstance(packet, SharkPacket)
        packet_number += 1
        # DEV: Uncomment below for specific step-through troubleshooting
        if DEBUG_PACKET_NUMBER and packet_number == DEBUG_PACKET_NUMBER:
            _log.info(f&#39;Investigate packet: {int(packet.number)}&#39;)
        try:
            packet_stats.packet_add(packet)
        except NotImplementedError as err:
            if str(err) not in handled_exceptions:
                sio = io.StringIO()
                ei = sys.exc_info()
                tb = ei[2]
                traceback.print_exception(ei[0], ei[1], tb, None, sio)
                s = sio.getvalue()
                sio.close()
                stack = s.split(&#39;\n&#39;)
                #: each stack call is 2 lines, the last 2 lines are the error
                #:   so the last call meta is 4-deep and the call itself 3-deep
                last_call = stack[-4:-2]
                err_prefix = &#39;pyshark&#39;
                if &#39;fieldedge_pcap/pcap.py&#39; in last_call[0]:
                    err_prefix = &#39;fieldedge_pcap&#39;
                _log.warning(f&#39;{err_prefix} (packet {packet.number}): {err}&#39;)
                handled_exceptions.append(str(err))
        except TSharkCrashException as err:
            _log.error(f&#39;tshark (packet {packet_number}): {err}&#39;)
            break
        except:
            #TODO: better error capture e.g. appears to have been cut short use editcap
            # https://tshark.dev/share/pcap_preparation/
            _log.exception(f&#39;Packet {packet_number} processing ERROR&#39;)
            break
    capture.close()
    if loop_is_new:
        loop.close()
    if queue is not None:
        queue.put(packet_stats)
    else:
        return packet_stats</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="fieldedge_pcap.pcap.Conversation"><code class="flex name class">
<span>class <span class="ident">Conversation</span></span>
<span>(</span><span>packet: pyshark.packet.packet.Packet = None, number: int = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Encapsulates all traffic between two endpoints.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>application</code></strong></dt>
<dd>The dominant application layer</dd>
<dt><strong><code>hosts</code></strong></dt>
<dd>A tuple of IP addresses (host A, host B)</dd>
<dt><strong><code>a_b</code></strong></dt>
<dd>The count of transactions from host A to host B</dd>
<dt><strong><code>b_a</code></strong></dt>
<dd>The count of transactions from host B to host A</dd>
<dt><strong><code>stream_id</code></strong></dt>
<dd>The stream ID from the tshark capture</dd>
<dt><strong><code>transport</code></strong></dt>
<dd>The transport used e.g. TCP, UDP</dd>
<dt><strong><code>ports</code></strong></dt>
<dd>A list of transport ports used e.g. [1883]</dd>
<dt><strong><code>start_ts</code></strong></dt>
<dd>The unix timestamp of the first packet sent</dd>
<dt><strong><code>packets</code></strong></dt>
<dd>A list of all the packets summarized</dd>
<dt><strong><code>packet_count</code></strong></dt>
<dd>The size of the packets list</dd>
<dt><strong><code>bytes_total</code></strong></dt>
<dd>The total number of bytes in the conversation</dd>
<dt><strong><code>bad_packet_count</code></strong></dt>
<dd>The number of suspected bad packets
(includes retransmit)</dd>
<dt><strong><code>bytes_bad</code></strong></dt>
<dd>The byte count of the suspected bad packets
(includes retransmitted bytes)</dd>
<dt><strong><code>retransmit_count</code></strong></dt>
<dd>The number of suspected retransmitted packets</dd>
<dt><strong><code>bytes_retransmit</code></strong></dt>
<dd>The total retransmitted bytes</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Conversation:
    &#34;&#34;&#34;Encapsulates all traffic between two endpoints.
    
    Attributes:
        application: The dominant application layer
        hosts: A tuple of IP addresses (host A, host B)
        a_b: The count of transactions from host A to host B
        b_a: The count of transactions from host B to host A
        stream_id: The stream ID from the tshark capture
        transport: The transport used e.g. TCP, UDP
        ports: A list of transport ports used e.g. [1883]
        start_ts: The unix timestamp of the first packet sent
        packets: A list of all the packets summarized
        packet_count: The size of the packets list
        bytes_total: The total number of bytes in the conversation
        bad_packet_count: The number of suspected bad packets
            (includes retransmit)
        bytes_bad: The byte count of the suspected bad packets
            (includes retransmitted bytes)
        retransmit_count: The number of suspected retransmitted packets
        bytes_retransmit: The total retransmitted bytes

    &#34;&#34;&#34;
    def __init__(self, packet: SharkPacket = None, number: int = None):
        self.number = number
        self.application: str = None
        self.hosts: tuple = None
        self.a_b: int = 0
        self.b_a: int = 0
        self.stream_id: str = None
        self.transport: str = None
        self.ports: list = []
        self.packets: &#39;list[SimplePacket]&#39; = []
        self.packet_count: int = 0
        self.bad_packet_count: int = 0
        self.retransmit_count: int = 0
        self.bytes_total: int = 0
        self.bytes_bad: int = 0
        self.bytes_retransmit: int = 0
        self.start_ts: float = None
        if packet is not None:
            self.packet_add(packet)
    
    def __repr__(self) -&gt; str:
        return json.dumps(vars(self), indent=2)

    def is_packet_in_flow(self, packet: SharkPacket) -&gt; bool:
        &#34;&#34;&#34;Returns True if the packet is between the object&#39;s hosts.
        
        Args:
            packet: A pyshark Packet capture
        
        Returns:
            True if the packet source and destination are the hosts.
        &#34;&#34;&#34;
        if self.hosts is None:
            return False
        (src, dst) = _get_src_dst(packet)
        if _is_local_traffic(packet):
            return False
        stream_id = None
        if packet.transport_layer:
            transport = packet.transport_layer
            try:
                stream_id = packet[transport].stream
            except AttributeError as err:
                _log.exception(f&#39;{err}&#39;)
        elif hasattr(packet, &#39;icmp&#39;) and packet[&#39;icmp&#39;].udp_stream:
            stream_id = packet[&#39;icmp&#39;].udp_stream
        if (src in self.hosts and dst in self.hosts and
            stream_id is not None and
            stream_id == self.stream_id):
            return True
        return False
    
    def packet_add(self, packet: SharkPacket) -&gt; bool:
        &#34;&#34;&#34;Adds the packet summary and metadata to the Conversation.
        
        Args:
            packet: A pyshark Packet capture
        
        Returns:
            True if the packet was added to the Conversation.
        
        Raises:
            ValueError if the packet is missing transport_layer or has a
                different transport or stream ID than the conversation.

        &#34;&#34;&#34;
        if not(isinstance(packet, SharkPacket)):
            raise ValueError(&#39;packet is not a valid pyshark Packet&#39;)
        if self.hosts is None:
            self.hosts = _get_src_dst(packet)
        elif not(self.is_packet_in_flow(packet)):
            _log.warning(f&#39;Packet {packet.number} not in flow {self.number}&#39;)
            return False
        try:
            simple_packet = SimplePacket(packet, self.hosts)
        except Exception as err:
            _log.error(err)
            raise err
        isotime = datetime.utcfromtimestamp(simple_packet.timestamp).isoformat()[0:23]
        if DEBUG_VERBOSE:
            _log.debug(f&#39;Adding packet {packet.number}&#39;
                       f&#39; to conversation {self.number or 0}:&#39;
                       f&#39;{isotime}|{simple_packet.application}|&#39;
                       f&#39;({simple_packet.transport}.{simple_packet.stream_id}&#39;
                       f&#39;:{simple_packet.dstport})&#39;
                       f&#39;|{simple_packet.size} bytes&#39;
                       f&#39;|{simple_packet.src}--&gt;{simple_packet.dst}&#39;)
        if simple_packet.src == self.hosts[0]:
            self.a_b += 1
        else:
            self.b_a += 1
        if self.transport is None:
            self.transport = simple_packet.transport
        if simple_packet.srcport not in self.ports:
            self.ports.append(simple_packet.srcport)
        if simple_packet.dstport not in self.ports:
            self.ports.append(simple_packet.dstport)
        if self.stream_id is None:
            self.stream_id = simple_packet.stream_id
        elif simple_packet.stream_id != self.stream_id:
            err = (f&#39;Packet {packet.number} expected stream {self.stream_id}&#39;
                   f&#39; but got {simple_packet.stream_id}&#39;)
            _log.error(err)
            raise ValueError(err)
        self.packet_count += 1
        self.bytes_total += simple_packet.size
        if self.start_ts is None:
            self.start_ts = simple_packet.timestamp
        try:
            if simple_packet.bad_packet:
                if &#39;analysis_retransmission&#39; in simple_packet.bad_packet:
                    self.retransmit_count += 1
                    self.bytes_retransmit += simple_packet.size
                self.bad_packet_count += 1
                self.bytes_bad += simple_packet.size
                if DEBUG_VERBOSE:
                    _log.debug(f&#39;Bad packet {packet.number}&#39;
                               f&#39; ({simple_packet.bad_packet})&#39;)
            self.packets.append(simple_packet)
            if self.application is None:
                self.application = simple_packet.application
            elif self.application != simple_packet.application:
                _log.warning(f&#39;Packet {packet.number}&#39;
                             f&#39; expected application {self.application}&#39;
                             f&#39; but got {simple_packet.application}&#39;)
            return True
        except Exception as err:
            _log.exception(err)
            raise err
        
    @staticmethod
    def _get_intervals_by_length(packets_by_size: dict) -&gt; dict:
        intervals = {}
        for packet_size in packets_by_size:
            packet_list: list[SimplePacket] = packets_by_size[packet_size]
            intervals[packet_size] = None
            if len(packet_list) == 1:
                application = packet_list[0].application
                application += f&#39;_{packet_size}B&#39;
                intervals[application] = None
                del intervals[packet_size]
                continue
            is_same_application = True   # starting assumption
            for i, packet in enumerate(packet_list):
                if i == 0:
                    # skip the first one since we are looking for time between
                    continue
                if (packet_list[i - 1].application != packet.application):
                    is_same_application = False
                this_interval = (
                    packet.timestamp - packet_list[i - 1].timestamp
                )
                if intervals[packet_size] is None:
                    intervals[packet_size] = this_interval
                else:
                    intervals[packet_size] = (round((intervals[packet_size] +
                                              this_interval) / 2, 3))
            if is_same_application:
                application = packet_list[0].application
            else:
                application = &#39;mixed&#39;
            application += f&#39;_{packet_size}B&#39;
            intervals[application] = intervals[packet_size]
            del intervals[packet_size]
        return intervals
    
    def data_series_packet_size(self) -&gt; list:
        &#34;&#34;&#34;Generates a data series with timestamp and packet size.

        Example: [(12345.78, 42), (12355.99, 42)]

        Returns:
            A list of tuples consisting of (unix_timestamp, size_bytes)

        &#34;&#34;&#34;
        series = []
        for packet in self.packets:
            datapoint = (packet.timestamp, packet.size)
            series.append(datapoint)
        return series

    def data_series_packet_size_good_bad(self) -&gt; &#39;tuple[list, list]&#39;:
        good_series = []
        bad_series = []
        for packet in self.packets:
            datapoint = (packet.timestamp, packet.size)
            if not packet.bad_packet:
                good_series.append(datapoint)
            else:
                bad_series.append(datapoint)
        return (good_series, bad_series)

    def group_packets_by_size(self) -&gt; tuple:
        &#34;&#34;&#34;Creates dictionaries keyed by similar packet size and direction.
        
        Returns:
            A tuple with 2 dictionaries representing flows A-B and B-A.
            In each dictionary the keys are the packet size and the value
                is a list of the packets of that size.

        &#34;&#34;&#34;
        packets_a_b = {}
        packets_b_a = {}
        lengths = []
        for packet in self.packets:
            if packet.a_b:
                if packet.size not in packets_a_b:
                    packets_a_b[packet.size] = list()
                packets_a_b[packet.size].append(packet)
            else:
                if packet.size not in packets_b_a:
                    packets_b_a[packet.size] = list()
                packets_b_a[packet.size].append(packet)
            lengths.append(packet.size)
        return (packets_a_b, packets_b_a)

    def intervals(self) -&gt; dict:
        &#34;&#34;&#34;Analyzes the conversation and returns metrics in a dictionary.
        
        Returns:
            A dictionary including:
                * A (str): The host IP that initiated the conversation
                * B (str): The host IP opposite to A
                * AB_intervals (dict): A dictionary with grouped packet size
                average repeat interval A to B in seconds
                * AB_intervals (dict): A dictionary with grouped packet size
                average repeat interval B to A in seconds

        &#34;&#34;&#34;
        # sort by direction and packet size
        packets_a_b, packets_b_a = self.group_packets_by_size()
        # TODO: dominant packet list based on quantity * size
        return {
            &#39;hosts&#39;: self.hosts,
            &#39;AB_intervals&#39;: self._get_intervals_by_length(packets_a_b),
            &#39;BA_intervals&#39;: self._get_intervals_by_length(packets_b_a)
        }</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="fieldedge_pcap.pcap.Conversation.data_series_packet_size"><code class="name flex">
<span>def <span class="ident">data_series_packet_size</span></span>(<span>self) ‑> list</span>
</code></dt>
<dd>
<div class="desc"><p>Generates a data series with timestamp and packet size.</p>
<p>Example: [(12345.78, 42), (12355.99, 42)]</p>
<h2 id="returns">Returns</h2>
<p>A list of tuples consisting of (unix_timestamp, size_bytes)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def data_series_packet_size(self) -&gt; list:
    &#34;&#34;&#34;Generates a data series with timestamp and packet size.

    Example: [(12345.78, 42), (12355.99, 42)]

    Returns:
        A list of tuples consisting of (unix_timestamp, size_bytes)

    &#34;&#34;&#34;
    series = []
    for packet in self.packets:
        datapoint = (packet.timestamp, packet.size)
        series.append(datapoint)
    return series</code></pre>
</details>
</dd>
<dt id="fieldedge_pcap.pcap.Conversation.data_series_packet_size_good_bad"><code class="name flex">
<span>def <span class="ident">data_series_packet_size_good_bad</span></span>(<span>self) ‑> tuple[list, list]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def data_series_packet_size_good_bad(self) -&gt; &#39;tuple[list, list]&#39;:
    good_series = []
    bad_series = []
    for packet in self.packets:
        datapoint = (packet.timestamp, packet.size)
        if not packet.bad_packet:
            good_series.append(datapoint)
        else:
            bad_series.append(datapoint)
    return (good_series, bad_series)</code></pre>
</details>
</dd>
<dt id="fieldedge_pcap.pcap.Conversation.group_packets_by_size"><code class="name flex">
<span>def <span class="ident">group_packets_by_size</span></span>(<span>self) ‑> tuple</span>
</code></dt>
<dd>
<div class="desc"><p>Creates dictionaries keyed by similar packet size and direction.</p>
<h2 id="returns">Returns</h2>
<p>A tuple with 2 dictionaries representing flows A-B and B-A.
In each dictionary the keys are the packet size and the value
is a list of the packets of that size.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def group_packets_by_size(self) -&gt; tuple:
    &#34;&#34;&#34;Creates dictionaries keyed by similar packet size and direction.
    
    Returns:
        A tuple with 2 dictionaries representing flows A-B and B-A.
        In each dictionary the keys are the packet size and the value
            is a list of the packets of that size.

    &#34;&#34;&#34;
    packets_a_b = {}
    packets_b_a = {}
    lengths = []
    for packet in self.packets:
        if packet.a_b:
            if packet.size not in packets_a_b:
                packets_a_b[packet.size] = list()
            packets_a_b[packet.size].append(packet)
        else:
            if packet.size not in packets_b_a:
                packets_b_a[packet.size] = list()
            packets_b_a[packet.size].append(packet)
        lengths.append(packet.size)
    return (packets_a_b, packets_b_a)</code></pre>
</details>
</dd>
<dt id="fieldedge_pcap.pcap.Conversation.intervals"><code class="name flex">
<span>def <span class="ident">intervals</span></span>(<span>self) ‑> dict</span>
</code></dt>
<dd>
<div class="desc"><p>Analyzes the conversation and returns metrics in a dictionary.</p>
<h2 id="returns">Returns</h2>
<p>A dictionary including:
* A (str): The host IP that initiated the conversation
* B (str): The host IP opposite to A
* AB_intervals (dict): A dictionary with grouped packet size
average repeat interval A to B in seconds
* AB_intervals (dict): A dictionary with grouped packet size
average repeat interval B to A in seconds</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def intervals(self) -&gt; dict:
    &#34;&#34;&#34;Analyzes the conversation and returns metrics in a dictionary.
    
    Returns:
        A dictionary including:
            * A (str): The host IP that initiated the conversation
            * B (str): The host IP opposite to A
            * AB_intervals (dict): A dictionary with grouped packet size
            average repeat interval A to B in seconds
            * AB_intervals (dict): A dictionary with grouped packet size
            average repeat interval B to A in seconds

    &#34;&#34;&#34;
    # sort by direction and packet size
    packets_a_b, packets_b_a = self.group_packets_by_size()
    # TODO: dominant packet list based on quantity * size
    return {
        &#39;hosts&#39;: self.hosts,
        &#39;AB_intervals&#39;: self._get_intervals_by_length(packets_a_b),
        &#39;BA_intervals&#39;: self._get_intervals_by_length(packets_b_a)
    }</code></pre>
</details>
</dd>
<dt id="fieldedge_pcap.pcap.Conversation.is_packet_in_flow"><code class="name flex">
<span>def <span class="ident">is_packet_in_flow</span></span>(<span>self, packet: pyshark.packet.packet.Packet) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Returns True if the packet is between the object's hosts.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>packet</code></strong></dt>
<dd>A pyshark Packet capture</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>True if the packet source and destination are the hosts.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_packet_in_flow(self, packet: SharkPacket) -&gt; bool:
    &#34;&#34;&#34;Returns True if the packet is between the object&#39;s hosts.
    
    Args:
        packet: A pyshark Packet capture
    
    Returns:
        True if the packet source and destination are the hosts.
    &#34;&#34;&#34;
    if self.hosts is None:
        return False
    (src, dst) = _get_src_dst(packet)
    if _is_local_traffic(packet):
        return False
    stream_id = None
    if packet.transport_layer:
        transport = packet.transport_layer
        try:
            stream_id = packet[transport].stream
        except AttributeError as err:
            _log.exception(f&#39;{err}&#39;)
    elif hasattr(packet, &#39;icmp&#39;) and packet[&#39;icmp&#39;].udp_stream:
        stream_id = packet[&#39;icmp&#39;].udp_stream
    if (src in self.hosts and dst in self.hosts and
        stream_id is not None and
        stream_id == self.stream_id):
        return True
    return False</code></pre>
</details>
</dd>
<dt id="fieldedge_pcap.pcap.Conversation.packet_add"><code class="name flex">
<span>def <span class="ident">packet_add</span></span>(<span>self, packet: pyshark.packet.packet.Packet) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Adds the packet summary and metadata to the Conversation.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>packet</code></strong></dt>
<dd>A pyshark Packet capture</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>True if the packet was added to the Conversation.</p>
<h2 id="raises">Raises</h2>
<p>ValueError if the packet is missing transport_layer or has a
different transport or stream ID than the conversation.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def packet_add(self, packet: SharkPacket) -&gt; bool:
    &#34;&#34;&#34;Adds the packet summary and metadata to the Conversation.
    
    Args:
        packet: A pyshark Packet capture
    
    Returns:
        True if the packet was added to the Conversation.
    
    Raises:
        ValueError if the packet is missing transport_layer or has a
            different transport or stream ID than the conversation.

    &#34;&#34;&#34;
    if not(isinstance(packet, SharkPacket)):
        raise ValueError(&#39;packet is not a valid pyshark Packet&#39;)
    if self.hosts is None:
        self.hosts = _get_src_dst(packet)
    elif not(self.is_packet_in_flow(packet)):
        _log.warning(f&#39;Packet {packet.number} not in flow {self.number}&#39;)
        return False
    try:
        simple_packet = SimplePacket(packet, self.hosts)
    except Exception as err:
        _log.error(err)
        raise err
    isotime = datetime.utcfromtimestamp(simple_packet.timestamp).isoformat()[0:23]
    if DEBUG_VERBOSE:
        _log.debug(f&#39;Adding packet {packet.number}&#39;
                   f&#39; to conversation {self.number or 0}:&#39;
                   f&#39;{isotime}|{simple_packet.application}|&#39;
                   f&#39;({simple_packet.transport}.{simple_packet.stream_id}&#39;
                   f&#39;:{simple_packet.dstport})&#39;
                   f&#39;|{simple_packet.size} bytes&#39;
                   f&#39;|{simple_packet.src}--&gt;{simple_packet.dst}&#39;)
    if simple_packet.src == self.hosts[0]:
        self.a_b += 1
    else:
        self.b_a += 1
    if self.transport is None:
        self.transport = simple_packet.transport
    if simple_packet.srcport not in self.ports:
        self.ports.append(simple_packet.srcport)
    if simple_packet.dstport not in self.ports:
        self.ports.append(simple_packet.dstport)
    if self.stream_id is None:
        self.stream_id = simple_packet.stream_id
    elif simple_packet.stream_id != self.stream_id:
        err = (f&#39;Packet {packet.number} expected stream {self.stream_id}&#39;
               f&#39; but got {simple_packet.stream_id}&#39;)
        _log.error(err)
        raise ValueError(err)
    self.packet_count += 1
    self.bytes_total += simple_packet.size
    if self.start_ts is None:
        self.start_ts = simple_packet.timestamp
    try:
        if simple_packet.bad_packet:
            if &#39;analysis_retransmission&#39; in simple_packet.bad_packet:
                self.retransmit_count += 1
                self.bytes_retransmit += simple_packet.size
            self.bad_packet_count += 1
            self.bytes_bad += simple_packet.size
            if DEBUG_VERBOSE:
                _log.debug(f&#39;Bad packet {packet.number}&#39;
                           f&#39; ({simple_packet.bad_packet})&#39;)
        self.packets.append(simple_packet)
        if self.application is None:
            self.application = simple_packet.application
        elif self.application != simple_packet.application:
            _log.warning(f&#39;Packet {packet.number}&#39;
                         f&#39; expected application {self.application}&#39;
                         f&#39; but got {simple_packet.application}&#39;)
        return True
    except Exception as err:
        _log.exception(err)
        raise err</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol"><code class="flex name class">
<span>class <span class="ident">EthernetProtocol</span></span>
<span>(</span><span>value, names=None, *, module=None, qualname=None, type=None, start=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Mappings for Ethernet packet types.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class EthernetProtocol(Enum):
    &#34;&#34;&#34;Mappings for Ethernet packet types.&#34;&#34;&#34;
    ETH_TYPE_EDP = 0x00bb  # Extreme Networks Discovery Protocol
    ETH_TYPE_PUP = 0x0200  # PUP protocol
    ETH_TYPE_IP = 0x0800  # IP protocol
    ETH_TYPE_ARP = 0x0806  # address resolution protocol
    ETH_TYPE_AOE = 0x88a2  # AoE protocol
    ETH_TYPE_CDP = 0x2000  # Cisco Discovery Protocol
    ETH_TYPE_DTP = 0x2004  # Cisco Dynamic Trunking Protocol
    ETH_TYPE_REVARP = 0x8035  # reverse addr resolution protocol
    ETH_TYPE_8021Q = 0x8100  # IEEE 802.1Q VLAN tagging
    ETH_TYPE_8021AD = 0x88a8  # IEEE 802.1ad
    ETH_TYPE_QINQ1 = 0x9100  # Legacy QinQ
    ETH_TYPE_QINQ2 = 0x9200  # Legacy QinQ
    ETH_TYPE_IPX = 0x8137  # Internetwork Packet Exchange
    ETH_TYPE_IP6 = 0x86DD  # IPv6 protocol
    ETH_TYPE_PPP = 0x880B  # PPP
    ETH_TYPE_MPLS = 0x8847  # MPLS
    ETH_TYPE_MPLS_MCAST = 0x8848  # MPLS Multicast
    ETH_TYPE_PPPOE_DISC = 0x8863  # PPP Over Ethernet Discovery Stage
    ETH_TYPE_PPPOE = 0x8864  # PPP Over Ethernet Session Stage
    ETH_TYPE_LLDP = 0x88CC  # Link Layer Discovery Protocol
    ETH_TYPE_TEB = 0x6558  # Transparent Ethernet Bridging</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_8021AD"><code class="name">var <span class="ident">ETH_TYPE_8021AD</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_8021Q"><code class="name">var <span class="ident">ETH_TYPE_8021Q</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_AOE"><code class="name">var <span class="ident">ETH_TYPE_AOE</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_ARP"><code class="name">var <span class="ident">ETH_TYPE_ARP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_CDP"><code class="name">var <span class="ident">ETH_TYPE_CDP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_DTP"><code class="name">var <span class="ident">ETH_TYPE_DTP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_EDP"><code class="name">var <span class="ident">ETH_TYPE_EDP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_IP"><code class="name">var <span class="ident">ETH_TYPE_IP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_IP6"><code class="name">var <span class="ident">ETH_TYPE_IP6</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_IPX"><code class="name">var <span class="ident">ETH_TYPE_IPX</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_LLDP"><code class="name">var <span class="ident">ETH_TYPE_LLDP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_MPLS"><code class="name">var <span class="ident">ETH_TYPE_MPLS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_MPLS_MCAST"><code class="name">var <span class="ident">ETH_TYPE_MPLS_MCAST</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_PPP"><code class="name">var <span class="ident">ETH_TYPE_PPP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_PPPOE"><code class="name">var <span class="ident">ETH_TYPE_PPPOE</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_PPPOE_DISC"><code class="name">var <span class="ident">ETH_TYPE_PPPOE_DISC</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_PUP"><code class="name">var <span class="ident">ETH_TYPE_PUP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_QINQ1"><code class="name">var <span class="ident">ETH_TYPE_QINQ1</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_QINQ2"><code class="name">var <span class="ident">ETH_TYPE_QINQ2</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_REVARP"><code class="name">var <span class="ident">ETH_TYPE_REVARP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_TEB"><code class="name">var <span class="ident">ETH_TYPE_TEB</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts"><code class="flex name class">
<span>class <span class="ident">KnownTcpPorts</span></span>
<span>(</span><span>value, names=None, *, module=None, qualname=None, type=None, start=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Mappings for common registered/known application layer TCP ports.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class KnownTcpPorts(Enum):
    &#34;&#34;&#34;Mappings for common registered/known application layer TCP ports.&#34;&#34;&#34;
    SMTP = 25
    HTTP = 80
    HTTP_TLS = 443
    DNS = 53
    FTP = 20
    FTPC = 21
    TELNET = 23
    IMAP = 143
    RDP = 3389
    SSH = 22
    HTTP2 = 8080
    MODBUS = 502
    MODBUS_TLS = 802
    MQTT = 1883
    MQTT_TLS = 8883
    MQTT_SOCKET = 9001
    DOCKERAPI = 2375
    DOCKERAPI_TLS = 2376
    SRCP = 4303
    COAP = 5683
    COAP_TLS = 5684
    DNP2 = 19999
    DNP = 20000
    IEC60870 = 2404</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.COAP"><code class="name">var <span class="ident">COAP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.COAP_TLS"><code class="name">var <span class="ident">COAP_TLS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.DNP"><code class="name">var <span class="ident">DNP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.DNP2"><code class="name">var <span class="ident">DNP2</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.DNS"><code class="name">var <span class="ident">DNS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.DOCKERAPI"><code class="name">var <span class="ident">DOCKERAPI</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.DOCKERAPI_TLS"><code class="name">var <span class="ident">DOCKERAPI_TLS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.FTP"><code class="name">var <span class="ident">FTP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.FTPC"><code class="name">var <span class="ident">FTPC</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.HTTP"><code class="name">var <span class="ident">HTTP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.HTTP2"><code class="name">var <span class="ident">HTTP2</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.HTTP_TLS"><code class="name">var <span class="ident">HTTP_TLS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.IEC60870"><code class="name">var <span class="ident">IEC60870</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.IMAP"><code class="name">var <span class="ident">IMAP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.MODBUS"><code class="name">var <span class="ident">MODBUS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.MODBUS_TLS"><code class="name">var <span class="ident">MODBUS_TLS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.MQTT"><code class="name">var <span class="ident">MQTT</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.MQTT_SOCKET"><code class="name">var <span class="ident">MQTT_SOCKET</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.MQTT_TLS"><code class="name">var <span class="ident">MQTT_TLS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.RDP"><code class="name">var <span class="ident">RDP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.SMTP"><code class="name">var <span class="ident">SMTP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.SRCP"><code class="name">var <span class="ident">SRCP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.SSH"><code class="name">var <span class="ident">SSH</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownTcpPorts.TELNET"><code class="name">var <span class="ident">TELNET</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="fieldedge_pcap.pcap.KnownUdpPorts"><code class="flex name class">
<span>class <span class="ident">KnownUdpPorts</span></span>
<span>(</span><span>value, names=None, *, module=None, qualname=None, type=None, start=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Mappings for common registered/known application layer TCP ports.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class KnownUdpPorts(Enum):
    &#34;&#34;&#34;Mappings for common registered/known application layer TCP ports.&#34;&#34;&#34;
    SNMP = 161
    DNS = 53
    DHCP_QUERY = 67
    DHCP_RESPONSE = 68
    NTP = 123</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="fieldedge_pcap.pcap.KnownUdpPorts.DHCP_QUERY"><code class="name">var <span class="ident">DHCP_QUERY</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownUdpPorts.DHCP_RESPONSE"><code class="name">var <span class="ident">DHCP_RESPONSE</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownUdpPorts.DNS"><code class="name">var <span class="ident">DNS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownUdpPorts.NTP"><code class="name">var <span class="ident">NTP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fieldedge_pcap.pcap.KnownUdpPorts.SNMP"><code class="name">var <span class="ident">SNMP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="fieldedge_pcap.pcap.PacketStatistics"><code class="flex name class">
<span>class <span class="ident">PacketStatistics</span></span>
<span>(</span><span>source_filename: str = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Encapsulates packet-level statistics from a capture over time.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>conversations</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of Conversation elements for analyses.</dd>
<dt><strong><code>packet_count</code></strong> :&ensp;<code>int</code></dt>
<dd>The total number of packets</dd>
<dt><strong><code>bytes_total</code></strong> :&ensp;<code>int</code></dt>
<dd>The total amount of data in bytes</dd>
</dl>
<p>Creates a PacketStatistics object.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>source_filename</code></strong></dt>
<dd>An optional tie to the source pcap file</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PacketStatistics:
    &#34;&#34;&#34;Encapsulates packet-level statistics from a capture over time.
    
    Attributes:
        conversations (list): A list of Conversation elements for analyses.
        packet_count (int): The total number of packets
        bytes_total (int): The total amount of data in bytes

    &#34;&#34;&#34;
    def __init__(self,
                 source_filename: str = None,
                 ) -&gt; None:
        &#34;&#34;&#34;Creates a PacketStatistics object.
        
        Args:
            source_filename: An optional tie to the source pcap file

        &#34;&#34;&#34;
        self._source_filename: str = source_filename
        self.conversations: list[Conversation] = []
        self._packet_count: int = 0
        self._unhandled_packet_types: list = []
        self._unhandled_packet_count: int = 0
        self._local_packet_count: int = 0
        self._bytes_total: int = 0
        self._unhandled_bytes: int = 0
        self._local_bytes: int = 0
        self._first_packet_ts: float = None
        self._last_packet_ts: float = None
    
    @property
    def packet_count(self) -&gt; int:
        return self._packet_count
    
    @property
    def bytes_total(self) -&gt; int:
        return self._bytes_total
    
    @property
    def duration(self) -&gt; int:
        duration = int(self._last_packet_ts - self._first_packet_ts)
        if self._source_filename is not None:
            fileparts = str(self._source_filename.split(&#39;.pcap&#39;)[0]).split(&#39;_&#39;)
            try:
                file_duration = int(fileparts[len(fileparts) - 1])
                duration = max(file_duration, duration)
            except:
                pass
        return duration
    
    def packet_add(self, packet: SharkPacket) -&gt; None:
        &#34;&#34;&#34;Adds a packet to the statistics for analyses.
        
        Args:
            packet: A pyshark Packet object.

        &#34;&#34;&#34;
        self._packet_count += 1
        self._bytes_total += int(packet.length)
        ts = round(float(packet.sniff_timestamp), 3)
        if self._first_packet_ts is None:
            self._first_packet_ts = ts
        self._last_packet_ts = ts
        if hasattr(packet, &#39;arp&#39;):
            self._process_arp(packet)
        elif hasattr(packet, &#39;tcp&#39;) or hasattr(packet, &#39;udp&#39;):
            self._process_ip(packet)
        elif hasattr(packet, &#39;icmp&#39;):
            self._process_ip(packet)
        else:
            self._process_unhandled(packet)
    
    def _process_arp(self, packet: SharkPacket):
        arp_desc = f&#39;{packet.arp.src_proto_ipv4}--&gt;{packet.arp.dst_proto_ipv4}&#39;
        if not _is_local_traffic(packet):
            _log.warning(f&#39;Non-local ARP packet {arp_desc}&#39;)
        else:
            if DEBUG_VERBOSE:
                _log.debug(f&#39;Local ARP {arp_desc} (ignored from statistics)&#39;)

    def _process_ip(self, packet: SharkPacket):
        in_conversation = False
        if _is_local_traffic(packet):
            if DEBUG_VERBOSE:
                _log.debug(f&#39;Ignoring packet {packet.number} local traffic&#39;)
            self._local_packet_count += 1
            self._local_bytes += int(packet.length)
            return
        for conversation in self.conversations:
            if conversation.is_packet_in_flow(packet):
                conversation.packet_add(packet)
                in_conversation = True
                break
        if not in_conversation:
            conversation_number = len(self.conversations) + 1
            if DEBUG_VERBOSE:
                _log.debug(f&#39;Found new conversation ({conversation_number})&#39;)
            conversation = Conversation(packet, conversation_number)
            self.conversations.append(conversation)

    def _process_unhandled(self, packet: SharkPacket):
        packet_type = packet.highest_layer
        self._unhandled_packet_count += 1
        self._unhandled_bytes += int(packet.length)
        if packet_type not in self._unhandled_packet_types:
            _log.warning(f&#39;Packet {packet.number}&#39;
                         f&#39; unhandled packet type {packet_type}&#39;)
            self._unhandled_packet_types.append(packet_type)

    def data_series_application_size(self, split_bad: bool = False) -&gt; dict:
        &#34;&#34;&#34;Returns a set of data series by conversation application.
        
        Example: {&#39;MQTT&#39;: [(12345.67, 42)]}

        Args:
            split_bad: if True will split out bad packets as a series.

        Returns:
            A dictionary with keys showing the application and values are
                tuples with (unix_timestamp, size_in_bytes)

        &#34;&#34;&#34;
        multi_series = {}
        for conversation in self.conversations:
            app = conversation.application
            if app in multi_series:
                multi_series[app] = (multi_series[app] +
                    conversation.data_series_packet_size())
            else:
                multi_series[app] = conversation.data_series_packet_size()
            multi_series[app].sort(key=lambda tup: tup[0])
        return multi_series

    def analyze_conversations(self) -&gt; dict:
        &#34;&#34;&#34;Analyzes all conversations to produce a summary.
        
        Returns:
            A dict with keys as unique host pairs &#34;(&#39;A&#39;, &#39;B&#39;)&#34; summary dict:
                {
                    count: `int`,
                    applications: `list[str]`,
                    start_times: `list[float]`,
                    packet_intervals: {
                        AB_intervals: {
                            &#39;&lt;transport&gt;_&lt;protocol&gt;_&lt;bytesize&gt;&#39;: `int`|`None`,
                        },
                        BA_intervals: {
                            &#39;&lt;transport&gt;_&lt;protocol&gt;_&lt;bytesize&gt;&#39;: `int`|`None`,
                        }
                    },
                    repeat_mean: `int`,
                    repeat_stdev: `int`
                }

        &#34;&#34;&#34;
        results = {}
        for conversation in self.conversations:
            hosts_str = str(conversation.hosts)
            intervals = conversation.intervals()
            intervals.pop(&#39;hosts&#39;, None)
            bad_packet_count = conversation.bad_packet_count
            if hosts_str not in results:
                results[hosts_str] = {
                    &#39;count&#39;: 1,
                    &#39;applications&#39;: [conversation.application],
                    &#39;start_times&#39;: [conversation.start_ts],
                    &#39;packet_intervals&#39;: intervals,
                    &#39;bytes&#39;: conversation.bytes_total,
                    &#39;bad_packet_count&#39;: bad_packet_count,
                    &#39;bytes_bad&#39;: conversation.bytes_bad,
                    &#39;retransmit_count&#39;: conversation.retransmit_count,
                    &#39;retransmit_bytes&#39;: conversation.bytes_retransmit,
                }
            else:
                results[hosts_str][&#39;count&#39;] += 1
                app = conversation.application
                if app not in results[hosts_str][&#39;applications&#39;]:
                    results[hosts_str][&#39;applications&#39;].append(app)
                results[hosts_str][&#39;start_times&#39;].append(conversation.start_ts)
                prior = results[hosts_str][&#39;packet_intervals&#39;]
                results[hosts_str][&#39;packet_intervals&#39;] = {**prior, **intervals}
                results[hosts_str][&#39;bad_packet_count&#39;] += bad_packet_count
        for key in results:
            times = results[key][&#39;start_times&#39;]
            results[key][&#39;repeat_mean&#39;] = None
            results[key][&#39;repeat_stdev&#39;] = None
            if len(times) == 1:
                continue
            intervals = []
            for i, ts in enumerate(times):
                if i == 0:
                    continue
                intervals.append(ts - times[i - 1])
            if len(intervals) &gt; 1:
                results[key][&#39;repeat_mean&#39;] = int(statistics.mean(intervals))
                results[key][&#39;repeat_stdev&#39;] = int(statistics.stdev(intervals))
        return results
    
    def unique_host_pairs(self) -&gt; &#39;list[tuple]&#39;:
        &#34;&#34;&#34;Lists unique host pairs as tuples.&#34;&#34;&#34;
        results = []
        for conversation in self.conversations:
            if conversation.hosts not in results:
                results.append(conversation.hosts)
        return results</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="fieldedge_pcap.pcap.PacketStatistics.bytes_total"><code class="name">var <span class="ident">bytes_total</span> : int</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def bytes_total(self) -&gt; int:
    return self._bytes_total</code></pre>
</details>
</dd>
<dt id="fieldedge_pcap.pcap.PacketStatistics.duration"><code class="name">var <span class="ident">duration</span> : int</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def duration(self) -&gt; int:
    duration = int(self._last_packet_ts - self._first_packet_ts)
    if self._source_filename is not None:
        fileparts = str(self._source_filename.split(&#39;.pcap&#39;)[0]).split(&#39;_&#39;)
        try:
            file_duration = int(fileparts[len(fileparts) - 1])
            duration = max(file_duration, duration)
        except:
            pass
    return duration</code></pre>
</details>
</dd>
<dt id="fieldedge_pcap.pcap.PacketStatistics.packet_count"><code class="name">var <span class="ident">packet_count</span> : int</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def packet_count(self) -&gt; int:
    return self._packet_count</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="fieldedge_pcap.pcap.PacketStatistics.analyze_conversations"><code class="name flex">
<span>def <span class="ident">analyze_conversations</span></span>(<span>self) ‑> dict</span>
</code></dt>
<dd>
<div class="desc"><p>Analyzes all conversations to produce a summary.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt>A dict with keys as unique host pairs "('A', 'B')" summary dict:</dt>
<dt>{</dt>
<dt><code>
count</code></dt>
<dd><code>int</code>,
applications: <code>list[str]</code>,
start_times: <code>list[float]</code>,
packet_intervals: {
AB_intervals: {
'<transport><em><protocol></em><bytesize>': <code>int</code>|<code>None</code>,
},
BA_intervals: {
'<transport><em><protocol></em><bytesize>': <code>int</code>|<code>None</code>,
}
},
repeat_mean: <code>int</code>,
repeat_stdev: <code>int</code>
}</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def analyze_conversations(self) -&gt; dict:
    &#34;&#34;&#34;Analyzes all conversations to produce a summary.
    
    Returns:
        A dict with keys as unique host pairs &#34;(&#39;A&#39;, &#39;B&#39;)&#34; summary dict:
            {
                count: `int`,
                applications: `list[str]`,
                start_times: `list[float]`,
                packet_intervals: {
                    AB_intervals: {
                        &#39;&lt;transport&gt;_&lt;protocol&gt;_&lt;bytesize&gt;&#39;: `int`|`None`,
                    },
                    BA_intervals: {
                        &#39;&lt;transport&gt;_&lt;protocol&gt;_&lt;bytesize&gt;&#39;: `int`|`None`,
                    }
                },
                repeat_mean: `int`,
                repeat_stdev: `int`
            }

    &#34;&#34;&#34;
    results = {}
    for conversation in self.conversations:
        hosts_str = str(conversation.hosts)
        intervals = conversation.intervals()
        intervals.pop(&#39;hosts&#39;, None)
        bad_packet_count = conversation.bad_packet_count
        if hosts_str not in results:
            results[hosts_str] = {
                &#39;count&#39;: 1,
                &#39;applications&#39;: [conversation.application],
                &#39;start_times&#39;: [conversation.start_ts],
                &#39;packet_intervals&#39;: intervals,
                &#39;bytes&#39;: conversation.bytes_total,
                &#39;bad_packet_count&#39;: bad_packet_count,
                &#39;bytes_bad&#39;: conversation.bytes_bad,
                &#39;retransmit_count&#39;: conversation.retransmit_count,
                &#39;retransmit_bytes&#39;: conversation.bytes_retransmit,
            }
        else:
            results[hosts_str][&#39;count&#39;] += 1
            app = conversation.application
            if app not in results[hosts_str][&#39;applications&#39;]:
                results[hosts_str][&#39;applications&#39;].append(app)
            results[hosts_str][&#39;start_times&#39;].append(conversation.start_ts)
            prior = results[hosts_str][&#39;packet_intervals&#39;]
            results[hosts_str][&#39;packet_intervals&#39;] = {**prior, **intervals}
            results[hosts_str][&#39;bad_packet_count&#39;] += bad_packet_count
    for key in results:
        times = results[key][&#39;start_times&#39;]
        results[key][&#39;repeat_mean&#39;] = None
        results[key][&#39;repeat_stdev&#39;] = None
        if len(times) == 1:
            continue
        intervals = []
        for i, ts in enumerate(times):
            if i == 0:
                continue
            intervals.append(ts - times[i - 1])
        if len(intervals) &gt; 1:
            results[key][&#39;repeat_mean&#39;] = int(statistics.mean(intervals))
            results[key][&#39;repeat_stdev&#39;] = int(statistics.stdev(intervals))
    return results</code></pre>
</details>
</dd>
<dt id="fieldedge_pcap.pcap.PacketStatistics.data_series_application_size"><code class="name flex">
<span>def <span class="ident">data_series_application_size</span></span>(<span>self, split_bad: bool = False) ‑> dict</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a set of data series by conversation application.</p>
<p>Example: {'MQTT': [(12345.67, 42)]}</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>split_bad</code></strong></dt>
<dd>if True will split out bad packets as a series.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A dictionary with keys showing the application and values are
tuples with (unix_timestamp, size_in_bytes)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def data_series_application_size(self, split_bad: bool = False) -&gt; dict:
    &#34;&#34;&#34;Returns a set of data series by conversation application.
    
    Example: {&#39;MQTT&#39;: [(12345.67, 42)]}

    Args:
        split_bad: if True will split out bad packets as a series.

    Returns:
        A dictionary with keys showing the application and values are
            tuples with (unix_timestamp, size_in_bytes)

    &#34;&#34;&#34;
    multi_series = {}
    for conversation in self.conversations:
        app = conversation.application
        if app in multi_series:
            multi_series[app] = (multi_series[app] +
                conversation.data_series_packet_size())
        else:
            multi_series[app] = conversation.data_series_packet_size()
        multi_series[app].sort(key=lambda tup: tup[0])
    return multi_series</code></pre>
</details>
</dd>
<dt id="fieldedge_pcap.pcap.PacketStatistics.packet_add"><code class="name flex">
<span>def <span class="ident">packet_add</span></span>(<span>self, packet: pyshark.packet.packet.Packet) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a packet to the statistics for analyses.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>packet</code></strong></dt>
<dd>A pyshark Packet object.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def packet_add(self, packet: SharkPacket) -&gt; None:
    &#34;&#34;&#34;Adds a packet to the statistics for analyses.
    
    Args:
        packet: A pyshark Packet object.

    &#34;&#34;&#34;
    self._packet_count += 1
    self._bytes_total += int(packet.length)
    ts = round(float(packet.sniff_timestamp), 3)
    if self._first_packet_ts is None:
        self._first_packet_ts = ts
    self._last_packet_ts = ts
    if hasattr(packet, &#39;arp&#39;):
        self._process_arp(packet)
    elif hasattr(packet, &#39;tcp&#39;) or hasattr(packet, &#39;udp&#39;):
        self._process_ip(packet)
    elif hasattr(packet, &#39;icmp&#39;):
        self._process_ip(packet)
    else:
        self._process_unhandled(packet)</code></pre>
</details>
</dd>
<dt id="fieldedge_pcap.pcap.PacketStatistics.unique_host_pairs"><code class="name flex">
<span>def <span class="ident">unique_host_pairs</span></span>(<span>self) ‑> list[tuple]</span>
</code></dt>
<dd>
<div class="desc"><p>Lists unique host pairs as tuples.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def unique_host_pairs(self) -&gt; &#39;list[tuple]&#39;:
    &#34;&#34;&#34;Lists unique host pairs as tuples.&#34;&#34;&#34;
    results = []
    for conversation in self.conversations:
        if conversation.hosts not in results:
            results.append(conversation.hosts)
    return results</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="fieldedge_pcap.pcap.SimplePacket"><code class="flex name class">
<span>class <span class="ident">SimplePacket</span></span>
<span>(</span><span>packet: pyshark.packet.packet.Packet, parent_hosts: tuple)</span>
</code></dt>
<dd>
<div class="desc"><p>A simplified packet representation.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>a_b</code></strong> :&ensp;<code>bool</code></dt>
<dd>Direction of travel relative to parent conversation</dd>
<dt><strong><code>application</code></strong> :&ensp;<code>str</code></dt>
<dd>The analysis-derived application</dd>
<dt><strong><code>highest_layer</code></strong> :&ensp;<code>str</code></dt>
<dd>The highest Wireshark-derived packet layer</dd>
<dt><strong><code>timestamp</code></strong> :&ensp;<code>float</code></dt>
<dd>The unix timestamp of the capture to 3 decimal places</dd>
<dt><strong><code>size</code></strong> :&ensp;<code>int</code></dt>
<dd>Size in bytes</dd>
<dt><strong><code>transport</code></strong> :&ensp;<code>str</code></dt>
<dd>The transport type</dd>
<dt><strong><code>src</code></strong> :&ensp;<code>str</code></dt>
<dd>Source IP address</dd>
<dt><strong><code>dst</code></strong> :&ensp;<code>str</code></dt>
<dd>Destination IP address</dd>
<dt><strong><code>srcport</code></strong> :&ensp;<code>int</code></dt>
<dd>Source port</dd>
<dt><strong><code>dstport</code></strong> :&ensp;<code>int</code></dt>
<dd>Destination port</dd>
<dt><strong><code>bad_packet</code></strong> :&ensp;<code>dict</code></dt>
<dd>Metadata present if the packet is suspected to be bad</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SimplePacket:
    &#34;&#34;&#34;A simplified packet representation.
    
    Attributes:
        a_b (bool): Direction of travel relative to parent conversation
        application (str): The analysis-derived application
        highest_layer (str): The highest Wireshark-derived packet layer
        timestamp (float): The unix timestamp of the capture to 3 decimal places
        size (int): Size in bytes
        transport (str): The transport type
        src (str): Source IP address
        dst (str): Destination IP address
        srcport (int): Source port
        dstport (int): Destination port
        bad_packet (dict): Metadata present if the packet is suspected to be bad

    &#34;&#34;&#34;
    def __init__(self, packet: SharkPacket, parent_hosts: tuple) -&gt; None:
        self._parent_hosts = parent_hosts
        self.timestamp = round(float(packet.sniff_timestamp), 3)
        self.size = int(packet.length)
        self.transport = packet.transport_layer
        if packet.transport_layer:
            self.transport = packet.transport_layer
            self.stream_id = str(packet[self.transport].stream)
        elif hasattr(packet, &#39;icmp&#39;) and packet[&#39;icmp&#39;].udp_port:
            self.transport = &#39;UDP&#39;
            self.stream_id = str(packet[&#39;icmp&#39;].udp_stream)
        else:
            raise ValueError(&#39;Unable to determine transport&#39;
                                f&#39; for {packet.highest_layer} packet&#39;)
        self.src, self.dst = _get_src_dst(packet)
        self.srcport, self.dstport = _get_ports(packet)
        self.highest_layer = str(packet.highest_layer).upper()
        self.application = _get_application(packet)
        self.a_b = True if self.src == self._parent_hosts[0] else False
        self.bad_packet = _check_flags(packet)</code></pre>
</details>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="fieldedge_pcap" href="index.html">fieldedge_pcap</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="fieldedge_pcap.pcap.create_pcap" href="#fieldedge_pcap.pcap.create_pcap">create_pcap</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.is_private_ip" href="#fieldedge_pcap.pcap.is_private_ip">is_private_ip</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.is_valid_ip" href="#fieldedge_pcap.pcap.is_valid_ip">is_valid_ip</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.pcap_filename" href="#fieldedge_pcap.pcap.pcap_filename">pcap_filename</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.process_pcap" href="#fieldedge_pcap.pcap.process_pcap">process_pcap</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="fieldedge_pcap.pcap.Conversation" href="#fieldedge_pcap.pcap.Conversation">Conversation</a></code></h4>
<ul class="">
<li><code><a title="fieldedge_pcap.pcap.Conversation.data_series_packet_size" href="#fieldedge_pcap.pcap.Conversation.data_series_packet_size">data_series_packet_size</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.Conversation.data_series_packet_size_good_bad" href="#fieldedge_pcap.pcap.Conversation.data_series_packet_size_good_bad">data_series_packet_size_good_bad</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.Conversation.group_packets_by_size" href="#fieldedge_pcap.pcap.Conversation.group_packets_by_size">group_packets_by_size</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.Conversation.intervals" href="#fieldedge_pcap.pcap.Conversation.intervals">intervals</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.Conversation.is_packet_in_flow" href="#fieldedge_pcap.pcap.Conversation.is_packet_in_flow">is_packet_in_flow</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.Conversation.packet_add" href="#fieldedge_pcap.pcap.Conversation.packet_add">packet_add</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="fieldedge_pcap.pcap.EthernetProtocol" href="#fieldedge_pcap.pcap.EthernetProtocol">EthernetProtocol</a></code></h4>
<ul class="two-column">
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_8021AD" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_8021AD">ETH_TYPE_8021AD</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_8021Q" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_8021Q">ETH_TYPE_8021Q</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_AOE" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_AOE">ETH_TYPE_AOE</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_ARP" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_ARP">ETH_TYPE_ARP</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_CDP" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_CDP">ETH_TYPE_CDP</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_DTP" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_DTP">ETH_TYPE_DTP</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_EDP" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_EDP">ETH_TYPE_EDP</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_IP" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_IP">ETH_TYPE_IP</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_IP6" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_IP6">ETH_TYPE_IP6</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_IPX" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_IPX">ETH_TYPE_IPX</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_LLDP" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_LLDP">ETH_TYPE_LLDP</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_MPLS" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_MPLS">ETH_TYPE_MPLS</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_MPLS_MCAST" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_MPLS_MCAST">ETH_TYPE_MPLS_MCAST</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_PPP" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_PPP">ETH_TYPE_PPP</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_PPPOE" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_PPPOE">ETH_TYPE_PPPOE</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_PPPOE_DISC" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_PPPOE_DISC">ETH_TYPE_PPPOE_DISC</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_PUP" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_PUP">ETH_TYPE_PUP</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_QINQ1" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_QINQ1">ETH_TYPE_QINQ1</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_QINQ2" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_QINQ2">ETH_TYPE_QINQ2</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_REVARP" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_REVARP">ETH_TYPE_REVARP</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_TEB" href="#fieldedge_pcap.pcap.EthernetProtocol.ETH_TYPE_TEB">ETH_TYPE_TEB</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="fieldedge_pcap.pcap.KnownTcpPorts" href="#fieldedge_pcap.pcap.KnownTcpPorts">KnownTcpPorts</a></code></h4>
<ul class="two-column">
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.COAP" href="#fieldedge_pcap.pcap.KnownTcpPorts.COAP">COAP</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.COAP_TLS" href="#fieldedge_pcap.pcap.KnownTcpPorts.COAP_TLS">COAP_TLS</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.DNP" href="#fieldedge_pcap.pcap.KnownTcpPorts.DNP">DNP</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.DNP2" href="#fieldedge_pcap.pcap.KnownTcpPorts.DNP2">DNP2</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.DNS" href="#fieldedge_pcap.pcap.KnownTcpPorts.DNS">DNS</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.DOCKERAPI" href="#fieldedge_pcap.pcap.KnownTcpPorts.DOCKERAPI">DOCKERAPI</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.DOCKERAPI_TLS" href="#fieldedge_pcap.pcap.KnownTcpPorts.DOCKERAPI_TLS">DOCKERAPI_TLS</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.FTP" href="#fieldedge_pcap.pcap.KnownTcpPorts.FTP">FTP</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.FTPC" href="#fieldedge_pcap.pcap.KnownTcpPorts.FTPC">FTPC</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.HTTP" href="#fieldedge_pcap.pcap.KnownTcpPorts.HTTP">HTTP</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.HTTP2" href="#fieldedge_pcap.pcap.KnownTcpPorts.HTTP2">HTTP2</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.HTTP_TLS" href="#fieldedge_pcap.pcap.KnownTcpPorts.HTTP_TLS">HTTP_TLS</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.IEC60870" href="#fieldedge_pcap.pcap.KnownTcpPorts.IEC60870">IEC60870</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.IMAP" href="#fieldedge_pcap.pcap.KnownTcpPorts.IMAP">IMAP</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.MODBUS" href="#fieldedge_pcap.pcap.KnownTcpPorts.MODBUS">MODBUS</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.MODBUS_TLS" href="#fieldedge_pcap.pcap.KnownTcpPorts.MODBUS_TLS">MODBUS_TLS</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.MQTT" href="#fieldedge_pcap.pcap.KnownTcpPorts.MQTT">MQTT</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.MQTT_SOCKET" href="#fieldedge_pcap.pcap.KnownTcpPorts.MQTT_SOCKET">MQTT_SOCKET</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.MQTT_TLS" href="#fieldedge_pcap.pcap.KnownTcpPorts.MQTT_TLS">MQTT_TLS</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.RDP" href="#fieldedge_pcap.pcap.KnownTcpPorts.RDP">RDP</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.SMTP" href="#fieldedge_pcap.pcap.KnownTcpPorts.SMTP">SMTP</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.SRCP" href="#fieldedge_pcap.pcap.KnownTcpPorts.SRCP">SRCP</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.SSH" href="#fieldedge_pcap.pcap.KnownTcpPorts.SSH">SSH</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownTcpPorts.TELNET" href="#fieldedge_pcap.pcap.KnownTcpPorts.TELNET">TELNET</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="fieldedge_pcap.pcap.KnownUdpPorts" href="#fieldedge_pcap.pcap.KnownUdpPorts">KnownUdpPorts</a></code></h4>
<ul class="">
<li><code><a title="fieldedge_pcap.pcap.KnownUdpPorts.DHCP_QUERY" href="#fieldedge_pcap.pcap.KnownUdpPorts.DHCP_QUERY">DHCP_QUERY</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownUdpPorts.DHCP_RESPONSE" href="#fieldedge_pcap.pcap.KnownUdpPorts.DHCP_RESPONSE">DHCP_RESPONSE</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownUdpPorts.DNS" href="#fieldedge_pcap.pcap.KnownUdpPorts.DNS">DNS</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownUdpPorts.NTP" href="#fieldedge_pcap.pcap.KnownUdpPorts.NTP">NTP</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.KnownUdpPorts.SNMP" href="#fieldedge_pcap.pcap.KnownUdpPorts.SNMP">SNMP</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="fieldedge_pcap.pcap.PacketStatistics" href="#fieldedge_pcap.pcap.PacketStatistics">PacketStatistics</a></code></h4>
<ul class="">
<li><code><a title="fieldedge_pcap.pcap.PacketStatistics.analyze_conversations" href="#fieldedge_pcap.pcap.PacketStatistics.analyze_conversations">analyze_conversations</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.PacketStatistics.bytes_total" href="#fieldedge_pcap.pcap.PacketStatistics.bytes_total">bytes_total</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.PacketStatistics.data_series_application_size" href="#fieldedge_pcap.pcap.PacketStatistics.data_series_application_size">data_series_application_size</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.PacketStatistics.duration" href="#fieldedge_pcap.pcap.PacketStatistics.duration">duration</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.PacketStatistics.packet_add" href="#fieldedge_pcap.pcap.PacketStatistics.packet_add">packet_add</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.PacketStatistics.packet_count" href="#fieldedge_pcap.pcap.PacketStatistics.packet_count">packet_count</a></code></li>
<li><code><a title="fieldedge_pcap.pcap.PacketStatistics.unique_host_pairs" href="#fieldedge_pcap.pcap.PacketStatistics.unique_host_pairs">unique_host_pairs</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="fieldedge_pcap.pcap.SimplePacket" href="#fieldedge_pcap.pcap.SimplePacket">SimplePacket</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>